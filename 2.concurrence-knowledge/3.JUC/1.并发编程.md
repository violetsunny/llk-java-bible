## TPS/QPS
tps:每秒处理完成的事务数，指的是一次完整的操作序列，不可分割。
qps:每秒处理完成的请求查询数，指的是一次查询数据操作。

## 并发和并行
并发：同一段时间内，多次做同一件事。
并行：同时处理多个事情。

并发编程的三个重要特性
原子性 : 一次操作或者多次操作，要么所有的操作全部都得到执行并且不会受到任何因素的干扰而中断，要么都不执行。synchronized 可以保证代码片段的原子性。
可见性 ：当一个线程对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。volatile 关键字可以保证共享变量的可见性。
有序性 ：代码在执行的过程中的先后顺序不变，Java 在编译器以及运行期间的优化，会使得代码的执行顺序未必就是编写代码时候的顺序。volatile 关键字可以禁止指令进行重排序优化。

## 进程有哪几种状态
创建状态(new) ：进程正在被创建，尚未到就绪状态。
就绪状态(ready) ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
运行状态(running) ：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。
阻塞状态(waiting) ：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。
结束状态(terminated) ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。

## 进程间的通信常见的的有哪几种方式
管道/匿名管道(Pipes) ：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。
有名管道(Names Pipes) : 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道严格遵循先进先出(first in first out)。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。
信号(Signal) ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；
消息队列(Message Queuing) ：消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显式地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。消息队列克服了信号承载信息量少，管道只能承载无格式字 节流以及缓冲区大小受限等缺点。
信号量(Semaphores) ：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。
共享内存(Shared memory) ：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。
套接字(Sockets) : 此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。

## 进程的调度算法
1.先到先得服务(FCFS)调度算法 : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
2.短作业优先(SJF)的调度算法 : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
3.时间片轮转调度算法 : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。
4.多级反馈队列调度算法 ：前面介绍的几种进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前被公认的一种较好的进程调度算法，UNIX 操作系统采取的便是这种调度算法。
5.优先级调度 ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。

## 进程和线程
1.进程基本上相互独立，而线程存在于进程内，是进程的子集
2.进程拥有共享的资源，如内存空间等，供其内部的线程共享
3.进程之间的通信，同一机器可用IPC,不同机器可用http
4.线程相对简单，共享进程的内存，更轻量。

一个进程对应多个线程，线程是进程的子集，是进程内的执行单元。
进程是系统资源分配和调度的基本单位。
线程是比进程更小的能独立运行的基本单位。

## 线程间的同步的方式
1.同步锁，synchronized，AQS等
2.Wait/Notify

## 协程或纤程（Coroutines）
Quasar的Fiber对象创建

线程对应多个协程，进程也可以有多个协程。是一种用户态的轻量级线程。调度由程序控制，同一时间只有一个协程有运行权。直接操作栈，所以很小的内核切换开销；不加锁的访问全局变量，上下文切换非常快。
协程更适合处理 I/O 密集型的异步任务。

## 实现多线程有哪几种方法？
使用Runnable接口和继承Thread  callable可以返回结果  thread的run调用runnable的run,被重写了调用重写的run方法

execute是runnable 无返回，有异常栈
submit是callable 有返回，无异常栈，可以在get()时拿到

## Thread线程生命周期
在Java中，每个线程都会在JVM的内存中创建一个线程栈。线程栈占用的是非堆内存中的虚拟机栈空间。线程栈用于存储线程执行方法的局部变量、方法调用链等信息。每个线程的线程栈是独立的，线程间不共享线程栈空间，这也是为什么线程是可以独立执行的原因之一。

新建（创建对象未与操作系统相关联）、就绪（与操作系统关联）、运行、阻塞、等待、死亡

阻塞调用join、sleep  synchronized
等待 wait  lock.park
就绪 yield
正常退出，中断interrupt,stop可以结束线程  stop会强制停止线程。

sleep,join,wait 在调用interrupt打断时，打断标记为false，状态为runable标记为true，会结束线程
Join底层是wait
wait释放锁，sleep不释放锁。

使用退出标志，使线程正常退出，也就是当 run() 方法完成后线程中止。
使用 stop() 方法强行终止线程，直接结束后面不在执行，包括catch 或 finally。不推荐使用这个方法，该方法已被弃用。
使用 interrupt 方法中断线程。调用 interrupt() 方法仅仅是在当前线程中打一个停止的标记，并不是真的停止线程，代码中使用Thread.isInterrupted() 来判断当前线程是否被中断， sleep() 或者 wait() 这样的操作，我们只能通过中断来处理了，Thread.sleep() 和Object.wait()方法由于中断而抛出的异常，是会清除中断标记的，如果需要有处理就必须在捕获异常后进行Thread.currentThread().interrupt(); // 重新设置中断标记。

在操作系统中层面线程有 READY 和 RUNNING 状态，而在 JVM 层面只能看到 RUNNABLE 状态，所以 Java 系统一般将这两个状态统称为 RUNNABLE（运行中） 状态 。现在的时分（time-sharing）多任务（multi-task）操作系统架构通常都是用所谓的“时间分片（time quantum or time slice）”方式进行抢占式（preemptive）轮转调度（round-robin式）。这个时间分片通常是很小的，一个线程一次最多只能在 CPU 上运行比如 10-20ms 的时间（此时处于 running 状态），也即大概只有 0.01 秒这一量级，时间片用后就要被切换下来放入调度队列的末尾等待再次调度。（也即回到 ready 状态）。线程切换的如此之快，区分这两种状态就没什么意义了。

## 线程状态
新建 (New)：当通过 new Thread() 创建一个新的线程对象时，线程就处于新建状态，这个时候线程还没有开始运行。

运行(Runnable)：线程正在被 JVM 执行，但它也可能是在等待操作系统的某些资源，比如 CPU。系统中分为Ready和Running状态，JVM中合在一起。

阻塞(Blocked)：线程因为等待监视器锁而阻塞，获取监视器锁是为了进入同步块或在调用 wait 方法再notify后重入同步块。

等待(Waiting)：线程在调用 Object.wait、Thread.join 或 LockSupport.park 方法后，进入此状态。waiting 状态的线程是在等待另外一个线程执行特定的动作。

限时等待(Timed Waiting)：线程在调用 Thread.sleep、Object.wait(timeout)、Thread.join(timeout)、LockSupport.parkNanos 或 LockSupport.parkUntil 方法后，进入此状态。Timed Waiting 状态的线程也是在等待另外一个线程执行特定的动作，但是带有超期时间。

终止状态(Terminated)：这是线程完成执行后的状态。

## ThreadPool线程池参数
参数：
corePoolSize 核心线程数+1（如果服务器是cpu消耗多就与cpu核数一致，如果IO交互也多，可以在两倍这间）、
maxPoolSize 最大线程数,、keepAliveTime  普通线程的存活时间、allowCoreThreadTimeOut 允许超时时间、
workQueue 工作队列：
ArrayBlockingQueue 有界数组的阻塞队列，插入还是读取都需要获取锁（ReentrantLock重入锁），队列满时被阻塞，默认非公平的、
LinkedBlockingQuene 单向链表（入队和出队的锁不同），可以有界和无界（Int.MAX=21亿）、
SynchronousQueue 无界同步队列、
PriorityBlockingQueue 支持优先级排序的无界阻塞队列，指定初始大小后自动扩容
queuesize 队列大小、
handler 拒绝策略：
CallerRunsPolicy、当任务添加到线程池中被拒绝时，会让调用者运行被拒绝的任务。
AbortPolicy、当任务添加到线程池中被拒绝时，它将抛出 RejectedExecutionException 异常。
DiscardPolicy、当任务添加到线程池中被拒绝时，线程池将丢弃被拒绝的任务。就是不往队列添加或者不继续阻塞等待。
DiscardOldestPolicy 当任务添加到线程池中被拒绝时，线程池会放弃等待队列中最旧的未处理任务，然后将被拒绝的任务添加到等待队列中。
自定义Polocy:用MQ仍进去，让其他机器消费。任务很重要，又防止线程池爆掉。本质就是保存下来，也可以redis或者数据库。需要注意，你的任务(Runnable)是可以被序列化的，因为需要持久化。
运行机制：
线程池开启指定大小的核心线程数，需要执行任务在超过核心线程数后，任务将放入队列中，核心线程运行后会从队列中取任务。如果队列无大小任务会一直放入，如果队列有大小且放入的线程任务超过队列大小，就会开启普通线程，普通线程开启数是要小于等于(最大线程数-核心线程数)，普通线程会一起执行，运行完成会回收，核心线程不会回收，如果超过最大线程数+队列大小的线程会根据拒绝策略执行。
runwork执行任务，getTask获取任务，没有任务一直循环获取。
核心就是持续增加还是丢弃
使用高3位表示线程池状态，低29位表示线程数量 原子操作
shutdown 不会接受新的任务，会把以前的任务执行完
线程池懒加载的，在初始化线程池就加载线程需要用prestartAllCoreThreads()或者prestartCoreThread()方法
线程饥饿 线程需要等待其他线程的工作结果，然而没有其他线程不够所以一直拿不到一直运行。解决：不同的任务用不同的线程池。

## 如何设置线程池数量多少？
如果我们设置的线程池数量太小的话，如果同一时间有大量任务/请求需要处理，可能会导致大量的请求/任务在任务队列中排队等待执行，甚至会出现任务队列满了之后任务/请求无法处理的情况，或者大量任务堆积在任务队列导致 OOM。这样很明显是有问题的！ CPU 根本没有得到充分利用。
但是，如果我们设置线程数量太大，大量线程可能会同时在争取 CPU 资源，这样会导致大量的上下文切换，从而增加线程的执行时间，影响了整体执行效率。

Cpu密集型为核数+1 ，IO密集型为核数*期望利用率*（1/等待时间占比）  或2N
Runtime.getRuntime().availableProcessors(); 获取当前机器cpu核数

如何判断是 CPU 密集任务还是 IO 密集任务？
CPU 密集型简单理解就是利用 CPU 计算能力的任务比如你在内存中对大量数据进行排序。但凡涉及到网络读取，文件读取这类都是 IO 密集型，这类任务的特点是 CPU 计算耗费时间相比于等待 IO 操作完成的时间来说很少，大部分时间都花在了等待 IO 操作完成上。

## 什么时候发生线程上下文切换
多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次上下文切换。

情况：主动让出 CPU，比如调用了 sleep(), wait() 等。
时间片用完，因为操作系统要防止一个线程或者进程长时间占用CPU导致其他线程或者进程饿死。
调用了阻塞类型的系统中断，比如请求 IO，线程被阻塞。

## start() 和run()方法
new 一个 Thread，线程进入了新建状态。调用 start()方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 但是，直接执行 run() 方法，会把 run() 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。

## BlockingQueue
BlockingQueue,如果BlockQueue是空的,从BlockingQueue取东西的操作将会被阻断进入等待状态,直到BlockingQueue进了东西才会被唤醒.同样,如果BlockingQueue是满的,任何试图往里存东西的操作也会被阻断进入等待状态,直到BlockingQueue里有空间才会被唤醒继续操作.

## ExecutorService
线程池

当一个线程池里面的线程异常后:
执行方式是execute时,可以看到堆栈异常的输出。当执行方式是submit时,堆栈异常没有输出。但是调用Future.get()方法时，可以捕获到异常。不会影响线程池里面其他线程的正常执行。线程池会把这个线程移除掉，并创建一个新的线程放到线程池中。

好处：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。
提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

## Executors
newFiexedThreadPool
创建固定大小的线程池，核心线程数和最大线程数相同，linked队列无限大，开启指定大小的线程后都放入队列中，不会开启普通线程。任务结束不会回收。
newCachedThreadPool
缓存线程池，核心线程为0，最大线程数为int的最大值2147483648，超时60s,同步队列，也就是执行时会开启大量的普通线程，不开启核心线程。
newSingleThreadExecutor
单线程池，核心线程为1，最大线程为1，linked队列无限大，由单个线程不停的执行任务。用了装饰器模式，返回service不能改。
newScheduledThreadPool
定期调度线程，传入核心线程数，最大线程数为int的最大值，延迟队列。延迟队列使用了优先级队列，根据时间比较优先级。  job，其中schedule只执行一次，scheduleAtFixedRate固定的频率周期性执行，scheduleWithFixedDelay前一个任务完成后再按周期执行。

## java如何实现多线程之间的通讯和协作？
1.
final void wait() throws InterruptedException  
final void notify()  
final void notifyAll()  

2.AQS  await/signal

## 一个主线程开启10个子线程，10个子线程执行完毕后主线程继续，如何实现这样一个线程同步？
join  CountDownLatch

join可以顺序执行，a线程中开启b,b.join就是让b先执行等待b的执行完成，b线程中c.join，就是c先执行。执行顺序就是c,b,a

## Thread线程顺序执行
1.wait/notify
2.park/unpark condition.await/signal
3.join
4.阻塞队列

## ThreadLocal的作用及实现原理
线程副本，每个线程都是改变自己的副本并且不会和其他线程的副本冲突。ThreadLocal类主要解决的就是让每个线程绑定自己的值，可以将ThreadLocal类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。

1.某些数据是以线程为作用域并且不同线程具有不同的数据的副本时，就可以考虑用ThreadLocal。
2.复杂逻辑下的对象传递，比如监听器的传递，有些时候一个线程中的任务过于复杂，我们又需要监听器能够贯穿整个线程的执行过程。

采用ThreadLocal可以让监听器作为线程内的全局对象而存在，在线程内部只要通过get方法就可以获取到监听器。

ThreadLocal维护一个ThreadLocalMap容器,key是ThreadLocal对象，所以每个ThreadLocal都是获取自己的value。2倍扩容
ThreadLocal key是弱引用（weakRefernce），value是强引用。
Key弱引用在于如果没有强引用指向ThreadLocal他就应该被回收，然而如果关系一直在就不会被回收，所以需要弱引用，将key回收。而 value 是强引用。所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，ThreadLocalMap 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap 实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录，分为探测式清理和启发式清理。使用完 ThreadLocal方法后 最好手动调用remove()方法。

## InheritableThreadLocal
InheritableThreadLocal主要用于子线程创建时，需要自动继承父线程的ThreadLocal变量，方便必要信息的进一步传递。
不适用于线程池中使用。TransmittableThreadLocal解决了在线程池中切换和重用线程时获取上下文的问题（也可以是线程池中ThreadLocal传递的问题）。

TtlExecutors.getTtlExecutorService(poolExecutor);
TransmittableThreadLocal:TtlRunnable和TtlCallable包装类，用于读取原Thread的ThreadLocal对象及值并存于Runnable/Callable中，在执行run或者call方法的时候再将存于Runnable/Callable中的ThreadLocal对象和值读取出来，存入调用run或者call的线程中。
其核心操作就是 CRR（Capture/Replay/Restore），拷贝快照、重放快照、复原上下文。
可能有些人会疑惑为什么需要复原，线程池的线程每次执行的时候，如果用了 TTL 那执行的线程都会被覆盖上下文，没必要复原对吧？
其实也有人向作者提了这个疑问，回答是：
线程池满了且线程池拒绝策略使用的是『CallerRunsPolicy』，这样执行的线程就变成当前线程了，那肯定是要复原的，不然上下文就没了。
使用ForkJoinPool（包含并行执行Stream与CompletableFuture，底层使用ForkJoinPool）的场景，展开的ForkJoinTask会在调用线程中直接执行。

## 什么是Daemon线程？它有什么意义？
所谓后台(daemon)线程也是守护线程，是指在程序运行的时候在后台提供一种通用服务的线程，并且这个线程并不属于程序中不可或缺的部分。因此，当所有的非后台线程结束时，程序也就终止了，同时会杀死进程中的所有后台线程。反过来说，只要有任何非后台线程还在运行，程序就不会终止。必须在线程启动之前调用setDaemon()方法，才能把它设置为后台线程。注意：后台进程在不执行finally子句的情况下就会终止其run()方法。

## tomcat线程池
拒绝策略，在捕获异常后会再次重新尝试放入队列，如果不能再抛异常

线程池执行修改为判断如果小于最大线程且大于核心线程，创建普通线程去执行，如果大于最大线程才会放入队列

## CompletableFuture 异步编排
为了降低 CPU 的阻塞等待时间和提升资源的利用率，我们会使用CompletableFuture对调用流程进行编排，降低依赖之间的阻塞。

CompletableFuture使用的是基于Reactor模式的异步编程模型。采用回调的方式实现异步执行。支持lambda表达式，流式编程和运行，拆分--》加工--》汇总

Reactor模式是一种并发模式，用于处理服务请求，这些请求在被服务之前可能需要等待某些资源。在这种模式中，请求被提交给服务处理器，然后服务处理器将请求放入队列，然后通过调度器异步地处理这些请求。CompletableFuture内部使用了ForkJoinPool线程池来执行任务。

但是依然不能避免CPU无法充分利用的问题：
1.线程资源浪费瓶颈始终在 IO 等待上，导致 CPU 资源利用率较低。目前大部分服务是 IO 密集型服务，一次请求的处理耗时大部分都消耗在等待下游 RPC，数据库查询的 IO 等待中，此时线程仍然只能阻塞等待结果返回，导致 CPU 的利用率很低。
2.线程数量存在限制， 为了增加并发度，我们会给线程池配置更大的线程数，但是线程的数量是有限制的，Java 的线程模型是 1:1 映射平台线程的，导致 Java 线程创建的成本很高，不能无限增加。同时随着 CPU 调度线程数的增加，会导致更严重的资源争用，宝贵的 CPU 资源被损耗在上下文切换上。

api:
supplyAsync
是开启 CompletableFuture 异步调用链的方法。使用这个方法，会将supplier 封装为一个任务提交给 executor 执行，然后返回一个记录任务执行状态和结果的 CompletableFuture 对象。之后可以在这个 CompletableFuture 对象上挂接各种回调动作。所以说，supplyAsync 可以作为“流”的起点。
CompletableFuture.allOf
作用是将多个 CompletableFuture 合并成一个CompletableFuture。这又是一个非常有用的方法，我们可以用它实现类似于 Map/Reduce 或 Fork/Join 的功能。
join，get
可以让程序等future1 和 future2 都运行完了之后再继续执行。以阻塞方式得到结果，get会抛出检查时异常，join会抛出运行时异常。
exceptionally
可以对异步调用链在执行过程中抛出的异常进行处理。

## 异步编程
目前主流的异步编程可以分为四类模式：Promise、Actor、ReactiveX 和纤程（或者说协程）
异步编程避免死锁:1.业务逻辑不形成环 2.多个任务不要使用相同的执行器(线程池)

多个异步编程相串起来时需要注意：
1.不同节点的处理速度会再某个节点阻塞时OOM，比如A->B->C，A节点处理很快，B节点处理速度比较慢从而导致大量处理被阻塞在B节点会导致OOM，处理的方式为可以在AB节点机上缓冲区，或者将B节点的处理能力传导到A节点放慢A节点的速度（就是背压，让A节点能感受到B节点压力从而做出处理）。
2.如果A阻塞住，后面B和C就会非常闲置。需要调节BC的线程资源，将A的处理速度加快。

## fork/join
分治思想，分而治之，化整为零是很多技术和算法的思想根源。
创建和cpu相同的线程数
task对象调用complete，complete中再创建task方法。用了递归，要有退出条件

stream流式编程：
parallelStream使用的是ForkJoinPool线程池。ForkJoinPool是Java7提供的一个用于并行执行任务的线程池，它的主要用途是提高多线程程序的性能，比如你可以将一个大任务分割成多个小任务并行执行，系统会自动的使用ForkJoinPool来执行这些小任务。

ForkJoinPool线程池的线程数量默认等于处理器的核心数，也可以通过系统属性"java.util.concurrent.ForkJoinPool.common.parallelism"来进行设置。

ForkJoinPool线程池的工作方式就是基于工作窃取算法,分配任务的方式是采用了工作窃取算法（work-stealing algorithm）。每个线程都维护了一个双端队列（Deque），多核就会有多个队列，用来存储需要执行的任务（ForkJoinTask）,执行时会从队列的尾部获取任务。工作窃取算法允许空闲的线程（队列中没有任务）从其他线程的任务队列中窃取任务来执行，从而最大限度地利用了处理器的计算能力。

具体的分配过程如下：
当一个线程需要执行新的任务时，它会首先从自己的队列中取出任务来执行。
如果自己的队列中没有任务，那么它会从其他线程的队列中窃取任务来执行。
如果其他线程的队列也没有任务，那么线程会进入等待状态，直到有新的任务被添加进来。
当所有的任务都执行完毕，所有的线程都会进入等待状态，等待新的任务的到来。

## Disruptor 可替代有界队列完成高并发线程数据交换
disruptor框架是个高性能线程间消息传递库，支持发送多播事件，基本上是无锁状态，会为事件提前分配内存空间。
disruptor框架的底层结构是环形缓冲区RingBuffer

Disruptor：Disruptor的入口，主要封装了环形队列RingBuffer、消费者集合ConsumerRepository的引用；主要提供了获取环形队列、添加消费者、生产者向RingBuffer中添加事件（可以理解为生产者生产数据）的操作；
RingBuffer：Disruptor中队列具体的实现，底层封装了Object[]数组；在初始化时，会使用Event事件对数组进行填充，填充的大小就是bufferSize设置的值；此外，该对象内部还维护了Sequencer（序列生产器）具体的实现；
Sequencer：序列生产器，分别有MultiProducerSequencer（多生产者序列生产器） 和 SingleProducerSequencer（单生产者序列生产器）两个实现类。上面的例子中，使用的是SingleProducerSequencer；在Sequencer中，维护了消费者的Sequence（序列对象）和生产者自己的Sequence（序列对象）；以及维护了生产者与消费者序列冲突时候的等待策略WaitStrategy；
Sequence：序列对象，内部维护了一个long型的value，这个序列指向了RingBuffer中Object[]数组具体的角标。生产者和消费者各自维护自己的Sequence；但都是指向RingBuffer的Object[]数组；
Wait Strategy：等待策略。当没有可消费的事件时，消费者根据特定的策略进行等待；当没有可生产的地方时，生产者根据特定的策略进行等待；
Event：事件对象，就是我们Ringbuffer中存在的数据，在Disruptor中用Event来定义数据，并不存在Event类，它只是一个定义；
EventProcessor：事件处理器，单独在一个线程内执行，判断消费者的序列和生产者序列关系，决定是否调用我们自定义的事件处理器，也就是是否可以进行消费；
EventHandler：事件处理器，由用户自定义实现，也就是最终的事件消费者，需要实现EventHandler接口；

https://tech.meituan.com/2016/11/18/disruptor.html

1.JCTools：JCTools是Java Concurrency Tools的简称，是一个开源的并发工具库，提供了一些高性能的无锁数据结构，如队列、栈等。JCTools中的队列实现比Java标准库中的队列有更高的性能，因为它使用了无锁（lock-free）或者无竞争（wait-free）的算法。
2.Disruptor：Disruptor是LMAX公司开发的一个高性能的并发框架，其核心是一个环形队列（RingBuffer）。Disruptor的设计目标是实现极高的事件处理速率，其性能远超BlockingQueue。Disruptor通过使用RingBuffer，避免了队列的插入和删除操作，只需要简单的递增指针就可以实现数据的读写，大大提高了并发性能。
3.ConcurrentLinkedQueue：这是一个基于链接节点的无界线程安全队列，它使用了CAS操作，确保了高并发环境下的高性能。
4.LinkedTransferQueue：这是一个由链表结构组成的无界阻塞TransferQueue队列。相比于其他BlockingQueue，LinkedTransferQueue多了transfer()方法，可以在生产者和消费者之间直接传递元素。
5.MpscArrayQueue：这是JCTools库中的一个队列，它是一个无锁的、支持多生产者单消费者的队列，性能非常高。
6.FastFlow：这是一个开源的并发编程框架，它提供了一种无锁的并发队列实现。
7.Agrona：这是一个开源的数据结构和工具库，它提供了一种高性能的、无锁的环形缓冲区实现。

## 响应式编程
1.响应流必须是无阻塞的。
2.响应流必须是一个数据流。
3.它必须可以异步执行。
4.并且它也应该能够处理背压。
背压是反应流中的一个重要概念，可以理解为，生产者可以感受到消费者反馈的消费压力，并根据压力进行动态调整生产速率。

响应式更像于主动通知的方式（push），自身变化了通知订阅者，如果没有订阅者那就不做什么。区别于平时的主动获取的方式（pull）。

Flux和Mono都是Publisher<T>在Reactor 3实现。
Flux是多个事件，Flux.just(new ClientUser("felord.cn", "reactive"),new ClientUser("Felordcn", "Reactor"));
Mono是0-1事件，isAuthenticated ? Mono.just(new ClientUser("felord.cn", "reactive")) : Mono.empty();
同时可以像Stream Api一样使用类似map、flatmap等操作符（operator）来操作它们。
Flux<Integer> just = Flux.just(1, 2, 3, 4, 5, 6, 7);
Mono<Integer> last = just.last();
Mono<Integer> first = just.next();

取出对象数据：
我们应该使用 subscribe()方法以非阻塞的方式进行订阅。
只要发布者不再推送数据，我们就可以执行block方法获取Mono里面的值，block违背了响应式编程的原则。在响应式应用中，不鼓励执行block方法。

blockingHelloWorld()
.map() //包装转换
.fliter() //包装过滤   都是懒加载，只是包装
.doOnNext(result -> assertEquals(expected, result))  
.subscribe(); //真正执行

1.声明阶段   由上向下
2.指定订阅者阶段  
3.建立联系阶段   建立联系是订阅者需要由下向上回溯订阅之前的publisher。比如Flux.just().map.filter().subscribe()  subscribe找filter,map,just进行初始化建立调用关系。
4.订阅者请求阶段   由下向上寻找Subscription实现类，最终在 Subscription实现类的对象调用 request() ，触发 原始 Subscription 的Source 获得数据作为 onNext 的参数。
5.调用执行阶段  onNext()然后在开始从上到下执行。

onBackpressureBuffer 背压器
publishOn 异步调度
fromRunnable 异步

## 虚拟线程
当遇到大促或突发流量等场景导致服务承受的请求数增大时，为了保证每个请求在尽可能短的时间内返回，减少等待时间，我们之前总会采用以下方案：

扩大服务最大线程数：简单有效，由于存在下列问题，导致平台线程有最大数量限制，不能大量扩充。
系统资源有限导致系统线程总量有限，进而导致与系统线程一一对应的平台线程有限。
平台线程的调度依赖于系统的线程调度程序，当平台线程创建过多，会消耗大量资源用于处理线程上下文切换。
每个平台线程都会开辟一块大小约 1m 私有的栈空间，大量平台线程会占据大量内存。
垂直扩展，升级机器配置，水平扩展，增加服务节点：也就是俗称的升配扩容大法，效果好，也是最常见的方案，缺点是会增加成本，同时有些场景下扩容并不能 100% 解决问题。
采用异步/响应式编程方案：例如 RPC NIO 异步调用，WebFlux，Rx-Java 等非阻塞的基于 Ractor 模型的框架，使用事件驱动使得少量线程即可实现高吞吐的请求处理，拥有较好的性能与优秀的资源利用，缺点是学习成本较高兼容性问题较大，编码风格与目前的一请求一线程的模型差异较大，理解难度大，同时对于代码的调试比较困难。

那易于编写又方便提升性能的方案就是虚拟线程了。JDK21提供了与 Thread 完全一致的抽象 Virtual Thread（Project Loom的一部分）来应对这种经常阻塞的情况，阻塞仍然是会阻塞，但是换了阻塞的对象，由昂贵的平台线程（我理解这个就是服务线程）阻塞改为了成本很低的虚拟线程的阻塞，当代码调用到阻塞 API 例如 IO，同步，Sleep 等操作时，JVM 会自动把 Virtual Thread 从平台线程上卸载，平台线程就会去处理下一个虚拟线程，通过这种方式，提升了平台线程的利用率，让平台线程不再阻塞在等待上，从底层实现了少量平台线程就可以处理大量请求，提高了服务吞吐和 CPU 的利用率。

线程术语定义
操作系统线程（OS Thread）：由操作系统管理，是操作系统调度的基本单位。
平台线程（Platform Thread）：Java.Lang.Thread 类的每个实例，都是一个平台线程，是 Java 对操作系统线程的包装，与操作系统是 1:1 映射。我理解就是服务线程（Service Thread）
虚拟线程（Virtual Thread）：一种轻量级，由 JVM 管理的线程。对应的实例 java.lang.VirtualThread 这个类。
载体线程（Carrier Thread）：指真正负责执行虚拟线程中任务的平台线程。一个虚拟线程装载到一个平台线程之后，那么这个平台线程就被称为虚拟线程的载体线程。

JDK 中 java.lang.Thread 的每个实例都是一个平台线程。平台线程在底层操作系统线程上运行 Java 代码，并在代码的整个生命周期内独占操作系统线程，平台线程实例本质是由系统内核的线程调度程序进行调度，并且平台线程的数量受限于操作系统线程的数量。
而虚拟线程(Virtual Thread)它不与特定的操作系统线程相绑定。它在平台线程上运行 Java 代码，但在代码的整个生命周期内不独占平台线程。这意味着许多虚拟线程可以在同一个平台线程上运行他们的 Java 代码，共享同一个平台线程。同时虚拟线程的成本很低，虚拟线程的数量可以比平台线程的数量大得多。虚拟线程属于用户态轻量线程，由JVM进行管理调度。

而当多个虚拟线程进行同时挂载时，如果在一个平台线程上。JVM会根据调度分配，如果分配多个时间点执行则会由于执行没有完成会进行资源竞争；如果分配在同一个时间点执行则是按顺序执行不会有竞争问题。所以为了避免竞争导致性能下降可以加入锁机制，但是只能是java锁不能用synchronized，因为会造成平台线程的阻塞。

理论上单个平台线程占用的内存空间至少是 KB 级别的，而单个虚拟线程实例占用的内存空间是 byte 级别，两者的内存占用差距较大，这也是虚拟线程可以大批量创建的原因。根据压测看，平台线程和虚拟线程创建数量比例是1:8，性能提升是2-4倍。虚拟线程的堆栈是作为堆栈块对象存储在 Java 的堆中的，可以被 GC 回收，又降低了虚拟线程的占用。

虚拟线程适用场景
1、大量的 IO 阻塞等待任务，例如下游 RPC 调用，DB 查询等。
2、大批量的处理时间较短的计算任务。
3、Thread-per-request (一请求一线程)风格的应用程序，例如主流的 Tomcat 线程模型或者基于类似线程模型实现的 SpringMVC 框架 ，这些应用只需要小小的改动就可以带来巨大的吞吐提升，不需要像webflux需要进行整体编码修改。
虚拟线程的局限及使用建议
1、虚拟线程存在 native 方法或者外部方法 (Foreign Function & Memory API，jep 424 ) 调用不能进行 yield 操作，此时载体线程会被阻塞。
2、当运行在 synchronized 修饰的代码块或者方法时，不能进行 yield 操作，此时载体线程会被阻塞，推荐使用 ReentrantLock，信号量等。
3、ThreadLocal 相关问题，目前虚拟线程仍然是支持 ThreadLocal 的，但是由于虚拟线程的数量非常多，会导致 Threadlocal 中存的线程变量非常多，需要频繁 GC 去清理，对性能会有影响，官方建议尽量少使用 ThreadLocal，同时不要在虚拟线程的 ThreadLocal 中放大对象，目前官方是想通过 ScopedLocal 去替换掉 ThreadLocal，但是在 21 版本还没有正式发布，这个可能是大规模使用虚拟线程的一大难题。
4、无需池化虚拟线程 虚拟线程占用的资源很少，因此可以大量地创建而无须考虑池化，它不需要跟平台线程池一样，平台线程的创建成本比较昂贵，所以通常选择去池化，去做共享，但是池化操作本身会引入额外开销，对于虚拟线程池化反而是得不偿失，使用虚拟线程我们抛弃池化的思维，用时创建，用完就扔。


使用：
Thread.startVirtualThread();
Thread.ofVirtual().unstarted();
Thread.ofVirtual().factory();
Executors.newVirtualThreadPerTaskExecutor();

## 虚拟线程实现
虚拟线程实现如下：virtual thread =continuation+scheduler+runnable。
虚拟线程会把任务（java.lang.Runnable实例）包装到一个 Continuation 实例中:
当任务需要阻塞挂起的时候，会调用 Continuation 的 yield 操作进行阻塞，虚拟线程会从平台线程卸载。
当任务解除阻塞继续执行的时候，调用 Continuation.run 会从阻塞点继续执行。

Scheduler 也就是执行器，由它将任务提交到具体的载体线程池中执行。
它是 java.util.concurrent.Executor 的子类。
虚拟线程框架提供了一个默认的 FIFO 的 ForkJoinPool 用于执行虚拟线程任务。

Runnable 则是真正的任务包装器，由 Scheduler 负责提交到载体线程池中执行。
JVM 把虚拟线程分配给平台线程的操作称为 mount（挂载），取消分配平台线程的操作称为 unmount（卸载）：
mount 操作：虚拟线程挂载到平台线程，虚拟线程中包装的 Continuation 堆栈帧数据会被拷贝到平台线程的线程栈，这是一个从堆复制到栈的过程。
unmount 操作：虚拟线程从平台线程卸载，此时虚拟线程的任务还没有执行完成，所以虚拟线程中包装的 Continuation 栈数据帧会会留在堆内存中。

从 Java 代码的角度来看，其实是看不到虚拟线程及载体线程共享操作系统线程的，会认为虚拟线程及其载体都在同一个线程上运行，因此，在同一虚拟线程上多次调用的代码可能会在每次调用时挂载的载体线程都不一样。JDK 中使用了 FIFO 模式的 ForkJoinPool 作为虚拟线程的调度器。

Continuation 组件十分重要，它既是用户真实任务的包装器，同时提供了虚拟线程任务暂停/继续的能力，以及虚拟线程与平台线程数据转移功能，当任务需要阻塞挂起的时候，调用 Continuation 的 yield 操作进行阻塞。当任务需要解除阻塞继续执行的时候，则调用 Continuation 的 run 恢复执行。同时Continuation 实例进行 yield 调用后，再次调用其 run 方法就可以从 yield 的调用之处继续往下执行，从而实现了程序的中断和恢复。

当遇到了阻塞(例如 Lock 等)场景，会触发 Continuation 的 yield 操作让出控制权，等待虚拟线程重新分配载体线程并且执行，虚拟线程中任务执行时候调用 Continuation#run() 先执行了部分任务代码，然后尝试获取锁，该操作是阻塞操作会导致 Continuation 的 yield 操作让出控制权，如果 yield 操作成功，会从载体线程 unmount，载体线程栈数据会移动到 Continuation 栈的数据帧中，保存在堆内存中，虚拟线程任务完成，此时虚拟线程和 Continuation 还没有终结和释放，载体线程被释放到执行器中等待新的任务；如果 Continuation 的 yield 操作失败，则会对载体线程进行 Park 调用，阻塞在载体线程上，此时虚拟线程和载体线程同时会被阻塞，本地方法和Synchronized 修饰的同步方法都会导致 yield 失败。当锁持有者释放锁之后，会唤醒虚拟线程获取锁，获取锁成功后，虚拟线程会重新进行 mount，让虚拟线程任务再次执行，此时有可能是分配到另一个载体线程中执行，Continuation 栈会的数据帧会被恢复到载体线程栈中，然后再次调用Continuation#run() 恢复任务执行。虚拟线程任务执行完成，标记 Continuation 终结，标记虚拟线程为终结状态，清空上下文变量，解除载体线程的挂载载体线程返还到调度器（线程池）中作为平台线程等待处理下一个任务。