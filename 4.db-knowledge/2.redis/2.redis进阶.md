## redis的数据类型映射
字符串（String）：可以存储 text、binary、protobuf 等格式的数据。
哈希（Hash）：可以存储 key-value 对，其中 key 和 value 可以是 text、binary、protobuf 等格式的数据。
列表（List）：可以存储一系列的值，这些值可以是 text、binary、protobuf 等格式的数据。
集合（Set）：可以存储一组无序且唯一的值，这些值可以是 text、binary、protobuf 等格式的数据。
有序集合（Sorted Set）：可以存储一组有序的值，这些值可以是 text、binary、protobuf 等格式的数据。

String 对应着 Redis 内部的 SDS （Simple Dynamic String），在 44 字节以内，使用 embstr 实现；超过了 44 字节，使用 raw 来存储。应用：分布式缓存，分布式全局ID，限流，分布式session
List 在数据少的时候对应着 ZipList，在数据多的时候对应着 LinkedList，并且 Redis 在 3.2 之后引入了 QuickList。应用：消息队列，发红包的场景
Hash 在数据少的时候对应着 ZipList，其他对应着 HashTable。条件：当哈希类型元素个数小于hash-max-ziplist-entries配置（默认512个）
所有值都小于hash-max-ziplist-value配置（默认64字节）。应用：购物车功能，对象类型数据
Set 对应着以IntSet或者HashTable来存储。对于Set来说，该HashTable的value值用于为NULL，通过key来存储元素。应用：标签管理功能，共同好友等
ZSet(Sorted set) 对应着 ZipList+Dict/SkipList。应用：排行榜系统
Geo 算经纬度
HyperLogLog 基数统计。应用：对数据进行统计
BitMap 对应String中的bit位。应用：记录只有0/1两种状态的数据,如男女，登录未登录等

text：文本格式，用于存储和表示人类可读的字符数据，如字符串、数字、标点符号等。
hex：十六进制格式，用于将二进制数据表示为十六进制字符串。这种格式可以使二进制数据更易于阅读和传输。
json：JavaScript 对象表示法（JSON）是一种轻量级的数据交换格式，易于阅读和编写，同时也易于机器解析和生成。JSON 通常用于表示结构化的数据，如对象、数组等。
binary：二进制格式，用于存储和表示原始的字节数据。二进制数据通常不易于阅读，但在存储和传输方面具有优势，因为它不需要额外的编码和解码过程。
msgpack：MessagePack 是一种二进制序列化格式，用于高效地编码和解码数据。它比 JSON 更紧凑，因此在存储和传输方面更高效。
unserialize：这是 PHP 中用于反序列化数据的函数。序列化是将数据结构或对象转换为一个字符串，以便在网络上传输或存储在文件中。反序列化是将序列化的字符串还原为原始数据结构或对象。
brotli、gzip、deflate、deflateraw：这些都是压缩算法，用于减小数据的大小以节省存储空间和加快传输速度。不同的压缩算法具有不同的压缩效率和速度特性，可以根据需要选择合适的算法。
protobuf：Protocol Buffers（Protobuf）是一种语言无关、平台无关的二进制序列化格式，由 Google 开发。它用于高效地编码和解码结构化数据，通常比 JSON 和 XML 等文本格式更紧凑和高效。

int类型,当一个key的value是整型时，Redis就将其编码为int类型。Redis默认会缓存10000个整型值（#define OBJ_SHARED_INTEGERS 10000），这就意味着，如果有10个不同的KEY，其value都是10000以内的值，事实上全部都是共享同一个对象.
embstr和raw编码的长度界限是44，在 44 字节以内，使用 embstr 实现；超过了 44 字节，使用 raw 来存储。embstr编码的字符串对象的所有数据都保存在一块连续的内存里面，所以这种编码的字符串对象比起raw编码的字符串对象能更好地利用缓存带来的优势。释放embstr编码的字符串对象只需要调用一次内存释放函数，而释放raw编码对象的字符串对象需要调用两次内存释放函数。
skiplist跳跃链表：score-value，就是按照得分进行跳过，就是你知道比当前分数大直接往后跳。
ziplist是将表中每一项存放在前后连续的地址空间内，一个ziplist整体占用一大块内存。它是一个表（list），但其实不是一个链表（linked list）。zip压缩结构
QuickList是一个双向链表，链表的每个节点保存一个ziplist
intset是整型数组，并且是一个有序的整型数组。
Dict 数据字典的实现是有两个 HashTable， 一般来说，只有一个有值；还有一个在扩容的时候需要。
hashtable对应的是HashMap，dict
linkedlist是List的一种编码数据结构非常简单，就是我们非常熟悉的双向链表，对应Java中的LinkedList。
Set是一个特殊的value为NULL的HashTable。
bitmap并不是一种真实的数据结构，它本质上是String数据结构，只不过操作的粒度变成了位，即bit。
streams底层的数据结构是radix tree，Radix Tree(基数树) 事实上就几乎相同是传统的二叉树
GEO数据结构可以在Redis中存储地理坐标，并且坐标有限制本身不是一种数据结构，它本质上还是借助于Sorted Set（ZSET），并且使用GeoHash技术进行填充。Redis中将经纬度使用52位的整数进行编码，放进zset(skiplist)中，score就是GeoHash的52位整数值。在使用Redis进行Geo查询时，其内部对应的操作其实就是zset(skiplist)的操作。通过zset的score进行排序就可以得到坐标附近的其它元素，通过将score还原成坐标值就可以得到元素的原始坐标。
HyperLogLog：16384 个bit桶。做流量统计。做去重基数统计的算法


hex：可以用于表示字符串、哈希、列表、集合和有序集合中的数据。
json：可以用于表示字符串、哈希、列表、集合和有序集合中的数据。
msgpack：可以用于表示字符串、哈希、列表、集合和有序集合中的数据。
unserialize：通常用于 PHP 序列化数据的反序列化，可以用于表示字符串、哈希、列表、集合和有序集合中的数据。
brotli、gzip、deflate、deflateraw：这些都是压缩算法，可以用于压缩字符串、哈希、列表、集合和有序集合中的数据以节省存储空间。在使用这些压缩算法时，需要在客户端进行压缩和解压缩操作。

## QuickList
typedef struct quicklist {
quicklistNode *head;    //指向quicklistNode头节点
quicklistNode *tail;    //指向quicklistNode的尾节点
unsigned long count;        /* 所有ziplist数据项的个数综合 */
unsigned long len;          /* quicklist节点个数*/
int fill : QL_FILL_BITS;              /* ziplist大小设置 */
unsigned int compress : QL_COMP_BITS; /* 节点压缩深度设置 */
unsigned int bookmark_count: QL_BM_BITS;
quicklistBookmark bookmarks[];
} quicklist;

当向list中添加元素时，会直接保存到某个QuickListNode中的ziplist中，不过不管是从头部插入数据，还是从尾部插入数据，都包含两种情况
如果头节点（尾部节点）上的ziplist大小没有超过限制，新数据会直接插入到ziplist中
如果头节点上的ziplist达到阈值，则创建一个新的quicklistNode节点，该节点中会创建一个ziplist，然后把这个新创建的节点插入到quicklist双向链表中。

## intset
typedef struct intset {
uint32_t encoding;
uint32_t length;
int8_t contents[];
} intset;

intset将整数元素按顺序存储在数组里，并通过二分法降低查找元素的时间复杂度。数据量大时，依赖于“查找”的命令（如SISMEMBER）就会由于O(logn)的时间复杂度而遇到一定的瓶颈，所以数据量大时会用dict来代替intset。
但是intset的优势就在于比dict更省内存，而且数据量小的时候O(logn)未必会慢于O(1)的hash function，这也是intset存在的原因。

## zset
ZSet的底层数据结构采用了zipList（压缩表）和skiplist（跳跃表）组成，当同时满足以下两个条件时，有序集合采用的是ziplist存储。
有序集合保存的元素个数要小于128个
有序集合保存的所有元素成员的长度必须小于64个字节
如果不能满足以上任意一个条件，有序集合会采用skiplist（跳跃表）结构进行存储，zSet不只是用skiplist，实际上，它使用了dict（字典表）和zskiplist（跳跃表）同时进行数据存储。

dict，字典类型， 其中key表示zset的成员数据，value表示zset的分值，用来支持O(1)复杂度的按照成员取分值的操作
zskiplist，跳跃表，按分值排序成员，用来支持平均复杂度为O(logn)的按照分值定位成员的操作，以及范围查找操作。
其中zskiplistNode中*obj和Dic中*key指向同一个具体元素，所以不会存在多余的内存消耗问题。另外，backward表示后退指针，方便进行回溯。

## skipList
跳表(skip list) 对标的是平衡树(AVL Tree)，是一种 插入/删除/搜索 都是 O(log n) 的数据结构。它最大的优势是原理简单、容易实现、方便扩展、效率更高。因此在一些热门的项目里用来替代平衡树，如 redis, leveldb 等。

跳表的基本思想：
首先，跳表处理的是有序的链表（一般是双向链表，下图未表示双向），如下：


这个链表中，如果要搜索一个数，需要从头到尾比较每个元素是否匹配，直到找到匹配的数为止，即时间复杂度是 O(n)。同理，插入一个数并保持链表有序，需要先找到合适的插入位置，再执行插入，总计也是 O(n)的时间。
那么如何提高搜索的速度呢？很简单，做个索引：



如上图，我们新创建一个链表，它包含的元素为前一个链表的偶数个元素。这样在搜索一个元素时，我们先在上层链表进行搜索，当元素未找到时再到下层链表中搜索。例如搜索数字 19 时的路径如下图：



先在上层中搜索，到达节点 17 时发现下一个节点为 21，已经大于 19，于是转到下一层搜索，找到的目标数字 19。
我们知道上层的节点数目为 n/2，因此，有了这层索引，我们搜索的时间复杂度降为了：O(n/2)。同理，我们可以不断地增加层数，来减少搜索的时间：




在上面的 4 层链表中搜索 25，在最上层搜索时就可以直接跳过 21 之前的所有节点，因此十分高效。
更一般地，如果有 k 层，我们需要的搜索次数会小于 ⌈n2k⌉+k ，这样当层数 k 增加到 ⌈log2n⌉时，搜索的时间复杂度就变成了 logn。其实这背后的原理和二叉搜索树或二分查找很类似，通过索引来跳过大量的节点，从而提高搜索效率。

动态跳表：
上节的结构是“静态”的，即我们先拥有了一个链表，再在之上建了多层的索引。但是在实际使用中，我们的链表是通过多次插入/删除形成的，换句话说是“动态”的。上节的结构要求上层相邻节点与对应下层节点间的个数比是 1:2，随意插入/删除一个节点，这个要求就被被破坏了。
因此跳表（skip list）表示，我们就不强制要求 1:2 了，一个节点要不要被索引，建几层的索引，都在节点插入时由抛硬币决定。当然，虽然索引的节点、索引的层数是随机的，为了保证搜索的效率，要大致保证每层的节点数目与上节的结构相当。下面是一个随机生成的跳表：



可以看到它每层的节点数还和上节的结构差不多，但是上下层的节点的对应关系已经完全被打破了。
现在假设节点 17 是最后插入的，在插入之前，我们需要搜索得到插入的位置：



接着，抛硬币决定要建立几层的索引，伪代码如下：
randomLevel()
lvl := 1
-- random() that returns a random value in [0...1)
while random() < p and lvl < MaxLevel do
lvl := lvl + 1
return lvl
上面的伪代码相当于抛硬币，如果是正面（random() < p）则层数加一，直到抛出反面为止。其中的 MaxLevel 是防止如果运气太好，层数就会太高，而太高的层数往往并不会提供额外的性能，
一般 MaxLevel=log1/pn。现在假设 randomLevel 返回的结果是 2，那么就得到下面的结果。



如果要删除节点，则把节点和对应的所有索引节点全部删除即可。当然，要删除节点时需要先搜索得到该节点，搜索过程中可以把路径记录下来，这样删除索引层节点的时候就不需要多次搜索了

## HyperLogLog
16384 个bit bruket ,是一种与 Bloom Filter 类似的算法，是用来做去重基数统计的算法，都是用准确度来换取时间和空间的估计算法。HyperLogLog 能够帮助我们节省大量存储空间和计算时间。HyperLogLog 插入和查询的时间复杂度都是 O(1)。HyperLogLog在数据量非常大的情况下，占用的存储空间非常小，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64（2的64次方） 个不同元素的基数.

PFADD 用于将元素添加到 HyperLogLog 寄存器；
PFCOUNT 用于返回添加到 HyperLogLog 寄存器中不同元素的个数（是一个估计值）；
PFMERGE 则用于合并多个 HyperLogLog 寄存器。
寄存器长度为 12K 字节时，估计误差为 0.81%；当寄存器长度是 256 字节时，估计误差为5.63%；当寄存器长度是 128 字节时，估计误差为 7.96%。
存放内容越大，误差越小。

## 3种常用的缓存读写策略
Cache Aside Pattern（旁路缓存模式）
写 ：
先更新 DB
然后直接删除 cache 。
读 :
从 cache 中读取数据，读取到就直接返回
cache中读取不到的话，就从 DB 中读取数据返回
再把数据放到 cache 中。

缺陷1：首次请求数据一定不在 cache 的问题。
解决办法：可以将热点数据可以提前放入cache 中。
缺陷2：写操作比较频繁的话导致cache中的数据会被频繁被删除，这样会影响缓存命中率 。
解决办法：
数据库和缓存数据强一致场景 ：更新DB的时候同样更新cache，不过我们需要加一个锁/分布式锁来保证更新cache的时候不存在线程安全问题。
数据库和缓存数据最终一致的场景 ：更新DB的时候同样更新cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小。

Read/Write Through Pattern（读写穿透）
写（Write Through）：
先查 cache，cache 中不存在，直接更新 DB。
cache 中存在，则先更新 cache，然后 cache 服务自己更新 DB（同步更新 cache 和 DB）。
读(Read Through)：
从 cache 中读取数据，读取到就直接返回 。
读取不到的话，先从 DB 加载，写入到 cache 后返回响应。

Write Behind Pattern（异步缓存写入）
Read/Write Through 是同步更新 cache 和 DB，而 Write Behind Caching 则是只更新缓存，不直接更新 DB，而是改为异步批量的方式来更新 DB。
Write Behind Pattern 下 DB 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。

