# 数据库设计的BC范式和三范式的区别
第一范式：保证每列的原子性
第二范式：保证一张表只描述一件事情
第三范式：保证每列都和主键直接相关

BC范式：比三范式更严格，消除数据冗余，保证数据一致性和完整性。就是数据关系只能通过一个唯一列关系，当出现m和n同时影响数据关系时，就需要拆分。
````
1. 订单和产品关系表
原始表：

订单号	销售区域	日期	销售代表	产品代码	数量
ORD1234	北区	2021/01/01	张三	P001	10
ORD1234	北区	2021/01/01	张三	P002	5
ORD5678	南区	2021/01/02	李四	P002	3
ORD5678	南区	2021/01/02	李四	P003	7
在这个例子中，“订单号”和“产品代码”一起形成了候选键。因此，“销售区域”、“日期”和“销售代表”必须完全依赖于这个键。如果其中一列只依赖其中的一部分，就需要将其从原表中分离出来。

规范化到BCNF后：

订单关系表：

订单号	销售代表	销售区域	日期
ORD1234	张三	北区	2021/01/01
ORD5678	李四	南区	2021/01/02
订单商品关系表：

订单号	产品代码	数量
ORD1234	P001	10
ORD1234	P002	5
ORD5678	P002	3
ORD5678	P003	7
现在，每个非主键属性都完全依赖于候选键，而不是只依赖于其中一部分。因此，这个关系满足BCNF
。
````

## Mysql 为什么选择B/B+Tree 以及这两者的差别
红黑树等结构也可以用来实现索引，但是文件系统及数据库系统普遍使用B/B+树结构来实现索引。
mysql是基于磁盘的数据库，索引是以索引文件的形式存在于磁盘中的，索引查询时要尽量减少磁盘IO的次数。
B+树更适合外部存储(一般指磁盘存储),
1、内节点(非叶子节点)不存储data，所以一个节点可以存储更多的内节点，每个节点能索引的范围更大更精确。也就是说使用B+树单次磁盘IO的信息量相比较B树更大，IO效率更高。
2、mysql是关系型数据库，经常会按照区间来访问某个索引列，B+树的叶子节点间按顺序建立了链指针，加强了区间访问性，所以B+树对索引列上的区间范围查询很友好。而B树每个节点的key和data在一起，无法进行区间查找。
3、B+树的查询效率更加稳定：所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。

根据B+树的特性，表中一定要有主键索引（Primary Key），没有的话Mysql会自动查找一个非NULL的属性，找不到则主动创建一个6byte的自增主键。

索引使用B+树实现，是为了让树深小，减少IO消耗，一个节点可以存16K的数，最大是2千万的数据量。而红黑树或者B数的缺点都是树深太大，多次IO,导致查询很慢。一张表索引最多16个。InnoDB 使用缓存为B+的横向分裂预留一部分内存页面，用来容纳可能的节点分裂。InnoDB 这种结构是牺牲了空间来获取对于读写的优化。
聚簇索引底层节点存索引和数据，聚簇索引只会有一个，底层是双向链表，而普通索引底层存的是指向聚簇索引的值（如果聚簇索引用的是id,存的是id）  联合索引会减少回表操作，因为如果要得值在索引里就不用回表，是覆盖索引。abc联合索引是将多个索引聚合存储，所以会先搜索a。

聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据，由于聚簇索引是将数据跟索引结构放到一块，因此一个表仅有一个聚簇索引。
聚簇索引默认是主键，如果表中没有定义主键，InnoDB 会选择一个唯一的非空索引代替。如果没有这样的索引，InnoDB 会隐式定义一个主键来作为聚簇索引。InnoDB 只聚集在同一个页面中的记录。包含相邻健值的页面可能相距甚远。如果你已经设置了主键为聚簇索引，必须先删除主键，然后添加我们想要的聚簇索引，最后恢复设置主键即可。
非聚簇索引：将数据存储与索引分开结构，索引结构的叶子节点存的是地址指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因。
执行引擎--》页缓存--》数据磁盘

## MySQL的B+树的高度怎么计算的呢？
InnoDB存储引擎最小储存单元是页，一页大小就是16k。B+树叶子存的是数据，内部节点存的是键值+指针。索引组织表通过非叶子节点的二分查找法以及指针确定数据在哪个页中，进而再去数据页中找到需要的数据，B+树结构图如下：

假设B+树的高度为2的话，即有一个根结点和若干个叶子结点。这棵B+树的存放总记录数为=根结点指针数*单个叶子节点记录行数。

如果一行记录的数据大小为1k，那么单个叶子节点可以存的记录数 =16k/1k =16.
非叶子节点内存放多少指针呢？我们假设主键ID为bigint类型，长度为8字节(面试官问你int类型，一个int就是32位，4字节)，而指针大小在InnoDB源码中设置为6字节，所以就是 8+6=14字节，16k/14B =16*1024B/14B = 1170个指针，可以指向1170个下层节点。
因此，一棵高度为2的B+树，能存放1170 * 16=18720条这样的数据记录。同理一棵高度为3的B+树，能存放1170 *1170 *16 =21902400，大概可以存放两千万左右的记录。B+树高度一般为1-3层，如果B+到了4层（256亿数据），查询的时候会多查磁盘的次数，SQL就会变慢。

注意：int最大值为21亿，所以到了4层就必须要用bigint(long)来存。

## Mysql存储引擎
InnoDB引擎：
将数据存储在表空间中，表空间由一系列的数据文件组成，由InnoDb管理
支持每个表的数据和索引存放在单独文件中(innodb_file_per_table)；
支持事务，采用MVCC来控制并发，并实现标准的4个事务隔离级别，支持外键。
索引基于聚簇索引建立，对主键查询有较高性能。
数据文件的平台无关性，支持数据在不同的架构平台移植
能够通过一些工具支持真正的热备，如XtraBackup等；
内部进行自身优化如采取可预测性预读，能够自动在内存中创建bash索引等
InnoDB 的存储文件有两个，后缀名分别是 .frm 和 .idb，其中 .frm 是表的定义文件，而 idb 是数据文件
InnoDB 中存在表锁和行锁，不过行锁是在命中索引的情况下才会起作用。所以要注意SQL的写法
MyISAM引擎：
MySQL5.1默认，不支持事务和行级锁,是表锁
提供大量的特性如全文索引、空间函数、压缩、延迟更新等
数据库故障后，安全恢复性，对于只读数据可以忍受故障恢复，MyISAM依然非常适用
日志服务器的场景也比较适用，只需插入和数据读取操作
不支持单表一个文件，会将所有的数据和索引内容分别存放在两个文件中
MyISAM对整张表加锁而不是对行，所以不适用写操作比较多的场景
支持索引缓存不支持数据缓存
Myisam 的存储文件有三个，后缀名分别是 .frm、.MYD、.MYI，其中 .frm 是表的定义文件，.MYD 是数据文件，.MYI 是索引文件。
Myisam 只支持表锁，且不支持事务。Myisam 由于有单独的索引文件，在读取数据方面的性能很高 。
InnoDB 和 Myisam 都是用 B+Tree 来存储数据的。
MEMORY存储引擎:
内存，表级锁。由于重启会丢数据，如果一个备库重启，会导致主备同步线程停止；如果主库跟这个备库是双 M 架构，还可能导致主库的内存表数据被删掉。
ARCHIVE存储引擎：
由于其支持压缩，故主要是用来做日志，流水等数据的归档
BDB存储引擎：
采用的是页面锁（page-level locking），但也支持表级锁

存储引擎是基于表的，而不是数据库。

## 什么是事务ACID
原子性（Atomicity）：原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。
一致性（Consistency）：事务前后数据的完整性和合法性校验必须保持一致。
隔离性（Isolation）：事务的隔离性是多个用户并发访问数据库时，数据库为每一个用户开启的事务，不能被其他事务的操作数据所干扰，多个并发事务之间要相互隔离。
持久性（Durability）：持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响

MySQL 只要保证每台数据库的 server_uuid 全局唯一，以及每台数据库生成的 transaction_id 自身唯一，就能保证 GTID 的全局唯一性。

只有保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。也就是说 A、I、D 是手段，C 是目的！

## Mysql事务隔离级别
Read uncommitted：读未提交，就是一个事务可以读取另一个未提交事务的数据，存在脏读问题。    脏写。
Read committed：读提交，就是一个事务要等另一个事务提交后才能读取数据，存在不可重复读问题，其他事务update导致，读取数据内容不一致。  丢失更新。  RC是很多公司建议的隔离级别，是为了增加并发度，减少锁的范围（间隙锁）。主从复制需要使用row格式。RC是读的当前数据，对于不符合条件的记录，锁会释放掉。RC是每次读取数据都生成一个ReadView
Repeatable read：可重复读，就是在开始读取数据（事务开启）时，不再允许修改操作，存在幻读问题，其他事务insert导致，读取数据数量不一致。 写偏序。   RR是Mysql默认的隔离级别，主要是为了主从复制一致。
RR的可重复读是读取到的数据没有发生改变(使用MVCC实现)，快照读。MVCC是通过undo log来做的，行级锁，非锁定读，加写锁。要触发next-key lock 可以解决幻读问题，MVCC是不能解决幻读的，但是MVCC+next-key lock解决幻读问题，所以RR是可以没有幻读，但不保证没有幻读。索引精确到唯一数据，不会触发next-key lock。 RR是在第一次读取数据时生成一个ReadView。
Serializable 串行 最高的事务隔离级别，在该级别下，事务串行化顺序执行，可以避免脏读、不可重复读与幻读。但是这种事务隔离级别效率低下，比较耗数据库性能，一般不使用。表锁

写异常：脏读--脏写，不可重复读--丢失更新，幻读--写偏序。
可重读允许幻读的产生。幻读是事务里面读取一组数据后，再次读取这组数据会发现它们可能已经被修改了。幻读对应的写异常是写偏序。写偏序从写入角度发现，事务内读取一批数据进行修改，由于幻读的存在，造成最终修改的结果从整体上看违背了数据一致性约束。
读已提交在可重读基础上放弃了不可重读。与幻读类似，但不可重读针对的是一条数据。也就是只读取一条数据，而后在同一个事务内，再读取它数据就变化了。

## 事务传播行为
PROPAGATION_REQUIRED（默认） 如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。
PROPAGATION_SUPPORTS 支持当前事务，如果当前没有事务，就以非事务方式执行。
PROPAGATION_MANDATORY 使用当前的事务，如果当前没有事务，就抛出异常。
PROPAGATION_REQUIRES_NEW 新建事务，如果当前存在事务，把当前事务挂起。外部方法的异常回滚不会影响内部事务回滚。
PROPAGATION_NOT_SUPPORTED 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。
PROPAGATION_NEVER 以非事务方式执行，如果当前存在事务，则抛出异常。
PROPAGATION_NESTED 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。

## 为什么一个数据查询操作还要启用事务支持呢？
MySQL 默认对每一个新建立的连接都启用了autocommit模式。在该模式下，每一个发送到 MySQL 服务器的sql语句都会在一个单独的事务中进行处理，执行结束后会自动提交事务，并开启一个新的事务。
1.如果你一次执行单条查询语句，则没有必要启用事务支持，数据库默认支持 SQL 执行期间的读一致性；
2.如果你一次执行多条查询语句，例如统计查询，报表查询，在这种场景下，多条查询 SQL 必须保证整体的读一致性，否则，在前条 SQL 查询之后，后条 SQL 查询之前，数据被其他用户改变，则该次整体的统计查询将会出现读数据不一致的状态，此时，应该启用事务支持

## Innodb在RR下怎么防止幻读
在 Repeatable Read 下 MVCC 防止了部分幻读，这边的 “部分” 是指在 一致性非锁定读 情况下，只能读取到第一次查询之前所插入的数据（根据 Read View 判断数据可见性，Read View 在第一次查询时生成）。但是！如果是 当前读 ，每次读取的都是最新数据，这时如果两次查询中间有其它事务插入数据，就会产生幻读。所以， InnoDB 在实现Repeatable Read 时，如果执行的是当前读，则会对读取的记录使用 Next-key Lock ，来防止其它事务在间隙间插入数据。

执行普通的 select 语句，会使用 一致性非锁定读（MVCC）。
select ... lock in share mode，select ... for update，insert、update、delete 操作，就是 锁定读（Locking Reads）也被称为 当前读（current read），才会触发Next-key Lock。另外对于使用索引(唯一索引和普通索引)的范围查询，排序，分组也会触发Next-key Lock。

## MySql的主从复制
Binary log：主数据库的二进制日志。Relay log：从服务器的中继日志。

第一步：master在每个事务更新数据完成之前，将该操作记录串行地写入到bin log文件中。

第二步：salve开启一个I/O Thread，该线程在master打开一个普通连接，主要工作是binlog dump process。如果读取的进度已经跟上了master，就进入睡眠状态并等待master产生新的事件。I/O线程最终的目的是将这些事件写入到relay log中继日志中。

第三步：SQL Thread会读取中继日志，并顺序执行该日志中的SQL事件，从而与主数据库中的数据保持一致。

## Mysql的主从延迟
谈到 MySQL 数据库主从同步延迟原理，得从 MySQL 的主从复制原理说起：

MySQL 的主从复制都是单线程的操作，主库对所有DML（操作数据）和 DDL（操作数据库表）产生 binlog，binlog 是顺序写，所以效率很高；
Slave 的 Slave_IO_Running 线程会到主库取日志，放入 relay log，效率会比较高；
Slave 的 Slave_SQL_Running 线程将主库的 DDL 和 DML 操作都在 Slave 实施，DML（操作数据）和 DDL（操作数据库表）的 IO 操作是随机的，不是顺序的，因此成本会很高，还可能是 Slave 上的其他查询产生 lock 争用，由于 Slave_SQL_Running 也是单线程的，所以一个 DDL 卡住了，需要执行 10 分钟，那么所有之后的 DDL 会等待这个 DDL 执行完才会继续执行，这就导致了延时。
总结一下主从延迟的主要原因：主从延迟主要是出现在 “relay log 回放” 这一步，当主库的 TPS 并发较高，产生的 DDL 数量超过从库一个 SQL 线程所能承受的范围，那么延时就产生了，当然还有就是可能与从库的大型 query 语句产生了锁等待。

情况：
从库机器性能：从库机器比主库的机器性能差，只需选择主从库一样规格的机器就好。
从库压力大：可以搞了一主多从的架构，还可以把 binlog 接入到 Hadoop 这类系统，让它们提供查询的能力。
从库过多：要避免复制的从节点数量过多，从库数据一般以3-5个为宜。
大事务：如果一个事务执行就要 10 分钟，那么主库执行完后，给到从库执行，最后这个事务可能就会导致从库延迟 10 分钟啦。日常开发中，不要一次性 delete 太多 SQL，需要分批进行，另外大表的 DDL 语句，也会导致大事务。
网络延迟：优化网络，比如带宽 20M 升级到 100M。
MySQL 版本低：低版本的 MySQL 只支持单线程复制，如果主库并发高，来不及传送到从库，就会导致延迟，可以换用更高版本的 MySQL，支持多线程复制。

## MySQL中sql的执行过程
连接器： 身份认证和权限相关(登录 MySQL 的时候)。
查询缓存： 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。
分析器： 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。
优化器： 按照 MySQL 认为最优的方案去执行。
执行器： 执行语句，然后从存储引擎返回数据。

1.查询
先检查该语句是否有权限，如果有权限，在 MySQL8.0 版本以前，会先查询缓存，以这条 SQL 语句为 key 在内存中查询是否有结果，如果有直接缓存。
通过分析器进行词法分析，判断这个 SQL 语句是否有语法错误
优化器进行确定执行方案（有时候不一定最好）
权限校验
执行器调用数据库引擎接口，返回引擎的执行结果
2.更新
分析器进行词法分析，判断是否有语法错误
权限校验
执行器执行语句调用引擎，引擎把数据保存在内存中，同时记录 redo log，此时 redo log 进入 prepare 状态。通知执行器可以提交。
执行器收到通知后记录 binlog，然后调用引擎接口，提交 redo log 为提交状态(commit状态)。

至于数据的更新，是在事务提交过程中先更新到buffer_pool中的，然后会根据刷盘策略进行更新。如果出现异常会根据redo log 和 binlog来保证数据一致性。

## MySQL 的并行策略
按表分发策略：
如果两个事务更新不同的表，它们就可以并行。因为数据是存储在表里的，所以按表分发，可以保证两个 worker 不会更新同一行。缺点：如果碰到热点表，比如所有的更新事务都会涉及到某一个表的时候，所有事务都会被分配到同一个 worker 中，就变成单线程复制了。

按行分发策略：
如果两个事务没有更新相同的行，它们在备库上可以并行执行。显然，这个模式要求 binlog 格式必须是 row。缺点：相比于按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的计算资源。

## Mysql中数据类型区别
VARCHAR(N) 中的 N 代表的是字符数，而不是字节数，使用 UTF8 存储 255 个汉字 Varchar(255)=765 个字节。过大的长度会消耗更多的内存。
MySQL没有布尔类型，通过整型0和1表示。常用tinyint(1)表示布尔型。

避免使用 TEXT,BLOB 数据类型，MySQL 内存临时表不支持 TEXT、BLOB 这样的大数据类型，如果查询中包含这样的数据，在排序等操作时，就不能使用内存临时表，必须使用磁盘临时表进行。而且对于这种数据，MySQL 还是要进行二次查询，会使 sql 性能变得很差，但不是说一定不能使用这样的数据类型。
如果一定要使用，建议把 BLOB 或是 TEXT 列分离到单独的扩展表中，查询时一定不要使用 select * 而只需要取出必要的列，不需要 TEXT 列的数据时不要对该列进行查询。

避免使用 ENUM 类型，修改 ENUM 值需要使用 ALTER 语句，ENUM 类型的 ORDER BY 操作效率低，需要额外操作。

尽可能把所有列定义为 NOT NULL，索引 NULL 列需要额外的空间来保存，所以要占用更多的空间，进行比较和计算时要对 NULL 值做特别的处理。

Decimal 类型为精准浮点数，在计算时不会丢失精度，占用空间由定义的宽度决定，每 4 个字节可以存储 9 位数字，并且小数点要占用一个字节，可用于存储比 bigint 更大的整型数据。

TIMESTAMP和DATETIME：
两者都可用来表示YYYY-MM-DD HH:MM:SS[.fraction]类型的日期

对于TIMESTAMP，它把客户端插入的时间从当前时区转化为UTC（世界标准时间）进行存储。查询时，将其又转化为客户端当前时区的时间进行返回。
对于DATETIME，不做任何改变，基本上是原样输入和输出。改变时区时会造成时间错误。

Timestamp 只需要使用 4 个字节的存储空间
DateTime 需要耗费 8 个字节的存储空间

timestamp所能存储的时间范围为：'1970-01-01 00:00:01.000000' 到 '2038-01-19 03:14:07.999999'。
datetime所能存储的时间范围为：'1000-01-01 00:00:00.000000' 到 '9999-12-31 23:59:59.999999'。

## 分库分表方法，多少数据开始分
按日期分、按key/hash分、取模分 %

先取模找到库，在通过日期找到表。只要数据放入的是符合条件的，那查出来的就是符合条件的。
提前先刷入大量的老数据。上线后双写（由于刷新数据有时间差，更新的时候会在新库中找不到数据，这时候双写需要将老库更新后数据插入新库中），读老库。把一周内的新数据同步过去，查看同一个时间有没有重复数据，有重复的数据不更新。切换读新库，没问题后写新库。通过配置。自增的Id是不能同步。
还有如果有并发更新的情况，在双写后需要先进行数据比对，通过job弥补数据差异后才能切换读库。

分库：是为了解决数据库连接资源不足问题，和磁盘IO的性能瓶颈问题。可以解决并发高的问题
分表：是为了解决单表数据量太大，sql语句查询数据时，即使走了索引也非常耗时问题。此外还可以解决消耗cpu资源问题。可以解决数据量大的问题
分库分表：可以解决 数据库连接资源不足、磁盘IO的性能瓶颈、检索数据耗时 和 消耗cpu资源等问题。可以解决大数据量和高并发的问题

如果你查的数据不能指定在哪个分区的话，多个分区的查询的IO超过了单表的IO次数，性能没有提升。所以在分库分表前，需要对历史查询比较多的sql进行分析，尽量查询数据打在一个分区中才能有性能提升。

既然range存在热点数据问题，hash取模扩容迁移数据比较困难，我们可以综合两种方案一起嘛，取之之长，弃之之短。
比较简单的做法就是，在拆分库的时候，我们可以先用range范围方案，比如订单id在0~4000万的区间，划分为订单库1;id在4000万~8000万的数据，划分到订单库2,将来要扩容时，id在8000万~1.2亿的数据，划分到订单库3。然后订单库内，再用hash取模的策略，把不同订单划分到不同的表。

分库分表之后，也会存在一些问题：
1.事务问题: 加入分布式事务
2.跨库关联: 分多次查询组合
3.排序问题: 跨节点的count,order by,group by以及聚合函数等问题：可以分别在各个节点上得到结果后在应用程序端进行合并。
4.分页问题
方案1：在个节点查到对应结果后，在代码端汇聚再分页。
方案2：把分页交给前端，前端传来pageSize和pageNo，在各个数据库节点都执行分页，然后汇聚总数量前端。这样缺点就是会造成空查，如果分页需要排序，也不好搞。
5.分布式ID: 改进后的雪花算法

目前流行的分库分表中间件比较多：
cobar
Mycat
Sharding-JDBC
Atlas
TDDL（淘宝）
vitess

## 表分区一般有哪两种手段？各有什么优缺点？
横向分区和纵向分区

用户维度放缓存，数据库可以按时间+订单号取模，查询条件必须加上时间。数据归档
mycat  主表-ER表  全局序列，用表做一个序列或者redis的incr自增命令

## 冷热数据分离,减小表的宽度
减少磁盘 IO,保证热数据的内存缓存命中率（表越宽，把表装载进内存缓冲池时所占用的内存也就越大,也会消耗更多的 IO）；

更有效的利用缓存，避免读入无用的冷数据；

经常一起使用的列放到一个表中（避免更多的关联操作）。

## MySql慢sql优化
Desc 查看索引使用情况，是否有全表扫描  
explain select_type 看是简单查询还是复杂查询 type是否用的索引  const代表打到索引 all是全表最差的  rows看扫描了多少数据，key 哪些索引。

type：system > const > eq_ref > ref > ref_or_null > index_merge > unique_subquery > index_subquery > range > index > ALL
system：这种类型要求数据库表中只有一条数据，是const类型的一个特例，一般情况下是不会出现的。
const：通过一次索引就能找到数据，一般用于主键或唯一索引作为条件，这类扫描效率极高，速度非常快。
eq_ref：常用于主键或唯一索引扫描，一般指使用主键的关联查询
ref : 常用于非主键和唯一索引扫描。
ref_or_null：这种连接类型类似于ref，区别在于MySQL会额外搜索包含NULL值的行
index_merge：使用了索引合并优化方法，查询使用了两个以上的索引。
unique_subquery：类似于eq_ref，条件用了in子查询
index_subquery：区别于unique_subquery，用于非唯一索引，可以返回重复值。
range：常用于范围查询，比如：between ... and 或 In 等操作
index：全索引扫描
ALL：全表扫描

Extra：Using index 没有回表和Using index condition 回表,filesort是使用临时文件排序消耗IO。可以通过联合索引避免回表，索引使用需要考虑排序使用联合索引。
Using filesort：表示按文件排序，一般是在指定的排序和索引排序不一致的情况才会出现。一般见于order by语句。磁盘临时文件产生大量IO消耗，减少TEXT,BLOB字段或者分开建表。如果order by没有出现filesort，则表明在内存中就排序完成。
Using index ：表示是否用了覆盖索引。不用回表
Using temporary: 表示是否使用了临时表,性能特别差，需要重点优化。一般多见于group by语句，或者union语句。
Using where : 表示使用了where条件过滤.
Using index condition：在存储引擎层进行数据过滤，而不是在服务层过滤，利用索引现有的数据减少回表的数据。

## 索引失效
1.like 索引不支持前模糊匹配
2.or 前后字段都要加索引
3.联合索引，没有使用索引中第一列
4.索引类型隐式转化 如字符串 没有加''转成int
5.使用not，<>，!=，<=>可以对null使用
6.对索引字段进行函数操作
7.使用is null，is not null
8.对索引字段进行运算，如：+-*/
9.左连接或者右连接查询关联的字段编码格式不一样，可能导致索引失效。
10.当全表扫描比索引快时，索引会失效。注：当表的索引被查询时，会使用最好的索引，除非优化器使用全表扫描更有效。
优化器优化成全表扫描取决与使用最好索引查出来的数据是否超过表的30%的数据。

## 类型隐式转化
1、两个参数至少有一个是NULL时，比较的结果也是NULL，特殊的情况是使用<=>对两个NULL做比较时会返回1，这两种情况都不需要做类型转换
2、两个参数都是字符串，会按照字符串来比较，不做类型转换
3、两个参数都是整数，按照整数来比较，不做类型转换
4、十六进制的值和非数字做比较时，会被当做二进制串
5、有一个参数是TIMESTAMP或DATETIME，并且另外一个参数是常量，常量会被转换为timestamp
6、有一个参数是decimal类型，如果另外一个参数是decimal或者整数，会将整数转换为decimal后进行比较，如果另外一个参数是浮点数，则会把decimal转换为浮点数进行比较
7、所有其他情况下，两个参数都会被转换为浮点数再进行比较

## SQL调优的手段有哪些？
用>=替换>，用>or<替换<>，用exists替换in
避免在有索引的字段上使用函数，明确的filter条件尽可能的写在where子句的后面，使用join替换子查询，避免使用Select *，不能使用NULL作为索引，尽可能避免全模糊查询，使用truncat代替delete删除全表，使用count(*)代替count(1)，使用exists代替distinct，使用where子句替换having子句。
注意limit偏移量。
排序走不到索引 话，会创建临时文件消耗的是IO资源。
left join 连接查询时需要注意过滤右表的条件需要放在on里，order by的字段不能是右表的。不然会有using temporary。
MAX(id) 比order by  id desc limit 1 性能更好。

UNION ALL 不会再对结果集进行去重操作，UNION 会把两个结果集的所有数据放到临时表中后再进行去重操作，不会有重复值时使用 UNION ALL 。

## 子查询性能差的原因
子查询的结果集无法使用索引，通常子查询的结果集会被存储到临时表中，不论是内存临时表还是磁盘临时表都不会存在索引，所以查询性能会受到一定的影响。特别是对于返回结果集比较大的子查询，其对查询性能的影响也就越大。

由于子查询会产生大量的临时表也没有索引，所以会消耗过多的 CPU 和 IO 资源，产生大量的慢查询。

## 就开发的角度来看，数据库性能优化的手段有哪些？
1、字段冗余
2、在常查询的字段上加上索引
3、表分区
4、SQL调优
5、如果需要替换原来字段的值，不要修改字段影响线上，应该新增字段，兼容

## 除了limit 其他分页方式
1.id自增可以范围查    in
2.top 不是标准sql

select * from test limit 300000,10; 是从300000开始取10个数.
selete * from test limit 10 offset 300000; 跳过300000，查出10个数.
limit偏移量过大是需要将跳过的记录加载到内存，如果内存不够可能会使用磁盘进行IO操作，会非常消耗性能。

select * from test a inner join (select id from test where val=4 limit 300000,5) b on a.id=b.id  子查询是找到300005的位置，并不会取出，外查询通过id索引获取。

## 并发insert
并发插入是会预占index（位置） ，再进行批量插入

## 模糊搜索的问题 % 和%% 和%%% 和%_%
% 和 %% 和%%%和 %_%
都能模糊查询所属有的数据

当项目使用mysql并对字段进行模糊搜索时，如果系统对字段的字符没有做到限制，就会经常出现用户输入下划线‘_’、百分号‘%’此类通配符进行搜索，如此执行往往会检索到错误的结果集，下滑线‘_’会匹配单个任意字符，百分号‘%’会匹配多个个任意字符。

解决方式：
1.like CONCAT('%',CONCAT('/','%','%')) ESCAPE '/'
2.like '%\%%'
3.INSTR (字段,输入的字符)  不走索引

## orderby
MySQL 会为每个线程分配一个内存（sort-buffer）用于排序该内存大小为 sort_buffer_size；

如果排序的数据量小于 sort_buffer_size，排序就会在内存中完成；

内部排序分为两种：
全字段排序：到索引树上找到满足条件的主键ID根据主键ID去取出数据放到sort_buffer然后进行快速排序
rowid排序：通过控制排序的行数据的长度来让sort_buffer中尽可能多的存放数据

如果数据量很大，内存中无法存下这么多，就会使用磁盘临时文件来辅助排序，称为外部排序；

外部排序:
MySQL会分为好几份单独的临时文件来存放排序后的数据，一般是磁盘文件中进行归并，然后将这些文件合并成一个大文件；在explan中是use filesort

## deleted
Mysql的删除不是直接物理删除，而是先打上标记，在达到一定阈值后一次性删除或者一致不删除。因为删除会导致B+的节点重新排列，锁表，影响数据库性能。

## grant,flush privileges
grant 展示和修改权限
grant语句会同时修改数据表和内存，判断权限的时候使用的内存数据，因此，规范使用是不需要加上 flush privileges 语句。
flush privileges 语句本身会用数据表的数据重建一份内存权限数据，所以在权限数据可能存在不一致的情况下再使用。

## count(*) count(1) count(列)
count(字段)遍历整张表，返回每行的值，判断字段是否为空，不为空+1。count(1)遍历整张表,不取值，每一行放一个1，判断不为空，累加。count(*)做了优化，遍历表，直接按行累，不取值不判断，直接按行累加。count(字段)<count(主键 id)<count(1)≈count(*)

因为COUNT(*)是SQL92定义的标准统计行数的语法，并且效率高，所以请直接使用COUNT(*)查询表的行数！

## MySQL的这个json特性
首先 MySql 里 JSON 字段的底层还是 blob，JSON对象是BLOB的子类,所以就是二进制字符串。（MySql 里字符串类型大体分两类，一类是“文本字符串”，另一类就是“二进制字符串”了）。MySql 采用了类似于 JsonPath 的语法、另外存储时 Key 有排序，所以 parser 可以在不用完整完全反序列化、而是仅仅反序列化所需要的字段的情况下完成工作，所以自然比你平常编程中用的那种 JSON 反序列化方法性能高很多。

查找
JSON_CONTAINS(json_doc, val[, path]) 指定path是否包含指定数据，包含返回1，否则返回0.如果有参数为NULL或path不存在，则返回null
JSON_EXTRACT(json_doc, path[, path] ...) 获得doc中某个或多个节点的值。
JSON_CONTAINS_PATH(json_doc, one_or_all, path[, path] ...) 检查是否存在指定路径，存在返回1，否则返回0.如果有参数为null,则返回null.
JSON_LENGTH(json_doc[, path])，返回数组的长度，如果是object则是属性个数，常量则为1

插入
update t set js=json_set('{"a":1,"s":"abc"}','$.a',456,'$.b','bbb') where id=1

## where 1=1影响性能吗？
不影响。

MySQL的优化器具有一项称为 Constant-Folding Optimization（常量折叠优化）的功能，可以从查询中消除重言式表达式。Constant-Folding Optimization 是一种编译器的优化技术，用于优化编译时计算表达式的常量部分，从而减少运行时的计算量，换句话说：Constant-Folding Optimization 是发生在编译期，而不是引擎执行期间。

如果一个公式，对于它的任一解释下其真值都为真，就称为重言式（永真式）。