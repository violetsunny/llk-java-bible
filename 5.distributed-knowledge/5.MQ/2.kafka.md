## kafka高性能原因
Kafka 是一个分布式流处理平台，它的高吞吐量、低延时、高可靠性、容错性、高可扩展性都使得Kafka非常适合作为流式平台。

「顺序读写」
kafka的消息是不断追加到文件中的，这个特性使kafka可以充分利用磁盘的顺序读写性能
顺序读写不需要硬盘磁头的寻道时间，只需很少的扇区旋转时间，所以速度远快于随机读写
Kafka 可以配置异步刷盘，不开启同步刷盘，异步刷盘不需要等写入磁盘后返回消息投递的 ACK，所以它提高了消息发送的吞吐量，降低了请求的延时

「零拷贝」
传统的 IO 流程，需要先把数据拷贝到内核缓冲区，再从内核缓冲拷贝到用户空间，应用程序处理完成以后，再拷贝回内核缓冲区
这个过程中发生了多次数据拷贝
为了减少不必要的拷贝，Kafka 依赖 Linux 内核提供的 Sendfile 系统调用
在 Sendfile 方法中，数据在内核缓冲区完成输入和输出，不需要拷贝到用户空间处理，这也就避免了重复的数据拷贝
在具体的操作中，Kafka 把所有的消息都存放在单独的文件里，在消息投递时直接通过 Sendfile 方法发送文件，减少了上下文切换，因此大大提高了性能

「MMAP技术」
除了 Sendfile 之外，还有一种零拷贝的实现技术，即 Memory Mapped Files
Kafka 使用 Memory Mapped Files 完成内存映射，Memory Mapped Files 对文件的操作不是 write/read，而是直接对内存地址的操作，如果是调用文件的 read 操作，则把数据先读取到内核空间中，然后再复制到用户空间，但 MMAP可以将文件直接映射到用户态的内存空间，省去了用户空间到内核空间复制的开销
Producer生产的数据持久化到broker，采用mmap文件映射，实现顺序的快速写入
Customer从broker读取数据，采用sendfile，将磁盘文件读到OS内核缓冲区后，直接转到socket buffer进行网络发送。

「批量发送读取」
Kafka 的批量包括批量写入、批量发布等。它在消息投递时会将消息缓存起来，然后批量发送
同样，消费端在消费消息时，也不是一条一条处理的，而是批量进行拉取，提高了消息的处理速度

「数据压缩」
Kafka还支持对消息集合进行压缩，Producer可以通过GZIP或Snappy格式对消息集合进行压缩
压缩的好处就是减少传输的数据量，减轻对网络传输的压力
Producer压缩之后，在Consumer需进行解压，虽然增加了CPU的工作，但在对大数据处理上，瓶颈在网络上而不是CPU，所以这个成本很值得

「分区机制」
kafka中的topic中的内容可以被分为多partition存在，每个partition又分为多个段segment，所以每次操作都是针对一小部分做操作，很轻便，并且增加并行操作的能力

## Kafka生产端
Kafka生产端是推送模式push。
发送消息到主题分区采用的分区策略有：轮询，随机，消息key，地理位置(适合跨城市地域部署的)；Kafka默认分区策略实际上同时实现了两种策略：如果指定了Key，那么默认实现按消息键保序策略；如果没有指定Key，则使用轮询策略。
避免重复消费只能靠参数调节，不能避免丢失消息。消息发送机制是通过调节器来积累到一定阈值后来发送。使用大数据非实时场景。

生产端主要是通过消息压缩、消息缓存批量发送、异步解耦等方面提升吞吐量的，发送一条消息需要经历 7 个步骤，步骤比较多，但其实这些步骤可以分为三大块，分别是 KafkaProducer 主线程、RecordAccumulator 缓存和 Sender 子线程。

KafkaProducer 主线程，主要负责创建信息，并调用拦截器、序列化器、分区器分别对消息进行拦截、序列化和路由分区，然后对消息进行压缩，把压缩过的消息放入 RecordAccumulator 缓存中。

RecordAccumulator 缓存，为每个分区创建了一个队列，这个队列是要发送到某个分区的消息集合。

Sender 子线程，是真正发送消息的线程。满足一定条件时，KafkaProducer 主线程会激活 Sender 子线程。Sender 子线程从 RecordAccumulator 缓存中拿到要发送的消息，并把消息交给底层网络组件来发送。对于网络接收和网络发送的数据，网络组件会通过两个缓存集合来维护：completedReceives 是负责保存完成的网络接收的集合，completedSends 是负责保存完成的网络发送的集合。服务端成功响应返回给 Sender 子线程后，Sender 子线程就会删除 RecordAccumulator 缓存内已经发送成功的消息。

生产端在异步的设计上体现到了两个方面：
第一个方面，KafkaProducer 主线程和 Sender 子线程各司其职，通过 RecordAccumulator 缓存交互数据。
KafkaProducer 主线程有同步和异步两种发送方式，但是这两者底层的实现是相同的，都是通过 Sender 子线程异步发送消息实现的。不同的地方是同步场景下主线程会等待 Sender 子线程发送完消息再返回，而异步是不等待 Sender 子线程发送完消息就返回了。
KafkaProducer 主线程发送消息时并不是真正的网络发送，而是将消息放入 RecordAccumulator 中缓存，然后主线程就从 send() 方法返回，之后 KafkaProducer 主线程会不断调用 send() 方法把消息缓存到 RecordAccumulator 中，而不去在意消息是否发送出去了。真正发送消息的是 Sender 子线程，Sender 子线程从 RecordAccumulator 缓存中取出消息，然后调用底层网络组件完成消息的发送。
注：在 RecordAccumulator 中有一个 CopyOnWriteMap 集合 batches。key 是主题分区，value 是 ProducerBatch 队列，每个分区都对应一个队列。队列中的元素是批次 ProducerBatch，消息就是封装在这些批次里进行缓存的。而消息发送的最小单位是 batch，也就是说一次消息发送可能不止一条消息，这样的设计大大减少了网络请求的次数，从而提升了网络读写的效率，进而提高了吞吐量。

生产端发送消息有两个过程：创建消息和网络发送消息。这两个过程都有可能出现阻塞，比如，消息的创建依赖远程数据库或缓存，如果网络不好，线程就会阻塞在消息创建上；而生产端和服务端的通信不好时，也会导致出现阻塞的问题。如果这两个过程放到一个线程里的话，那么其中有一个发送阻塞，就会影响另一个过程的执行。
第二个方面，Sender 子线程和 Kafka 底层通信模块解耦。
Sender 子线程最终是调用 Kafka 底层通信模块实现消息的发送和接收的。

## Kafka服务端
Broker负责接收和处理客户端发送过来的请求，以及对消息进行持久化。Broker上会存有多个主题，每个主题又分为不同的分区，分区中是消息队列，每个分区会有副本，副本分为leader副本和follower副本,副本是对相同数据的备份，follower副本不负责对外提供服务只会从leader拉取数据进行同步。分区中的消息会有偏移量offset。副本选举采用：ISR机制（同步副本机制）+优先副本的方式，并且每个broker上的分区副本不会有多个。

Broker在启动时，会尝试去ZooKeeper中创建/controller节点，是控制器。主要作用：主题管理（创建、删除、增加分区），分区重分配，Preferred领导者选举，集群成员管理（新增Broker、Broker主动关闭、Broker宕机），集群元数据信息。

服务端针对高吞吐有几个设计特点：网络层的 Reactor 设计模式、顺序写、页缓存和零拷贝。
1. 网络层的 Reactor 设计模式
   整个服务端的网络架构分为 4 个层次：①Acceptor 线程构成的连接创建层，负责创建和客户端的连接；②Processor 线程类构成的网络事件处理层；③由 RequestChannel 构成的请求和响应的缓冲层；④由 KafkaRequestHandler 和 KafkaApis 构成的真正的业务处理层。

这样的设计优势
第一，我们先思考为什么要把 Acceptor 线程和 Processor 线程分开。如果不分开，网络读写的量很大势必造成大量线程阻塞，导致服务端对 OP_ACCEPT 事件响应不及时，进而连接失败。同时，如果服务端刚启动瞬时来了很多连接，大量的线程都去建立新的连接了，那么网络读写事件的处理就会慢下来，也会引起读写超时等问题。
Acceptor 线程和 Processor 线程分为两层这样的设计让连接的创建和网络读写事件的处理分开，同时还可以配置 Processor 线程的数量，这样做不会被极端场景影响到整体的响应时间，同时也是符合 Reactor 设计模式的。（Reactor 模式又被称为反应器模式或应答者模式，是基于事件驱动的设计模式）
第二，Processor 线程解析完请求后并不是直接交给业务线程处理，而是放到 RequestChannel 的请求队列里，这样做避免在高并发场景下业务线程（即调用底层组件的线程）工作过于饱和而造成超时的情况出现。
第三，KafkaRequestHandlerPool 线程池先消费 RequestChannel 类里的请求队列，然后通过调用 KafkaApis 实现对底层组件的调用。这样做既可以实现网络处理和调用底层组件的解耦，也可以根据实际请求，随时调整 KafkaRequestHandlerPool 线程池的线程数，调整调用底层组件的能力。
第四，KafkaApis 类会把响应放入对应的 Processor 线程里的响应集合里，而不是直接让 Processor 把响应发送给客户端，这样做实现了业务线程和网络操作线程的解耦，避免了高并发时线程工作过于饱和而造成的延迟问题。

2. 顺序写
   Kafka 写日志文件的时候用的是追加消息的形式，只在文件尾部顺序写消息，同时在文件头部顺序读取消息。消息队列不涉及修改消息，所以不需要随机写。这样的设计即使用的是传统的磁盘，吞吐量也会很大。主要原因是操作系统对于顺序写和顺序读有优化，具体采用的是后写（对于写消息优化）和预读（对于读消息优化）。生产环境上经过测试，顺序写比随机写快 3 个数量级。

3. 页缓存
   页缓存简单说就是把缓存当磁盘用，这样就避免了频繁地读写磁盘。
   当一个进程要读取或写入磁盘文件的时候，系统会判断数据是否在内存中，如果在，就直接把内存中的数据返回给进程；如果不在，就读取磁盘文件，同时会多读一些连续的磁盘页放到内存中。这样下次再读取或写入时，系统会判断数据是否在内存中，只要是顺序地读写消息，命中率会很高的，大大减少了磁盘访问的次数，提高了服务端的吞吐量。

4. 零拷贝
   所谓“零拷贝”是 CPU 不参与拷贝数据的工作，可以节省大量的 CPU 周期，同时减少了两次 CPU 在用户态和内核态的切换。这样大大减少了 CPU 的负载，从而提升了吞吐量。

## Kafka消费端
Kafka消费端是拉取模式pull,采用的是长轮询的方式.
消费端拉取消息任务和网络 IO 任务是解耦的。网络 IO 任务会事先把消息拉取到消费者缓存里，然后等待拉取消息任务读取缓存里的消息。这样做的好处是拉取消息任务拉取消息的时候不会造成 IO 阻塞，可以提高拉取消息任务的效率，并最终提升整体的吞吐量。

Consumer Group订阅多个主题，主题下的分区只会分配给 Group下的一个实例(多分区对一个实例)。所以理想情况下，Consumer实例的数量应该等于该Group订阅主题的分区总数。Group之间彼此独立，互不影响。一个分区只能被同一个消费者组中的一个消费者消费，但是一个消费者可以消费多个分区。因此，分区和消费者之间的关系是 1:N。将分区和消费之间调整为1:1是比较合理的方式，kafka的consumer支持多线程（concurrency）
消费者分配策略：轮询，取余，Sticky（在消费者新增或者退出时减少重新分配，而是保持原有分配结果后平均）

kafka消费者本身不支持广播模式，但是可以通过每个消费者都定一个消费组id的方式进行广播。

重平衡：Rebalance,消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。
Rebalance是Kafka消费者端实现高可用的重要手段。发生时机：订阅主题发生变化，分区数发生变化，消费者发生变化。Rebalance会暂停消费造成积压。另外，如果响应过慢造成心跳超时变成假死也会Rebalance，而此时假死服务又加入了消费然后又超时可是会造成严重的积压问题。
1. 设置心跳间隔设置为比会话超时时间的三分之一。
2. 指定消费分区，负载过于复杂。
3. Sticky分配策略：均衡分配，分配分区数最多相差一个；分区重新分配时，尽量保留上一次的分配结果，减少不必要的变动。
4. 对消息进行topic细分，减少重分配影响范围。

Coordinator：协调者
所谓协调者，它专门为Consumer Group服务，负责为Group执行Rebalance以及提供位移管理和组成员管理等。
具体来讲，Consumer端应用程序在提交位移时，其实是向Coordinator所在的Broker提交位移，同样地，当Consumer应用启动时，也是向Coordinator所在的Broker发送各种请求，然后由Coordinator负责执行消费者组的注册、成员管理记录等元数据管理操作。
所有Broker在启动时，都会创建和开启相应的Coordinator组件。也就是说，「所有Broker都有各自的Coordinator组件」。
那么，Consumer Group如何确定为它服务的Coordinator在哪台Broker上呢？信息放在Kafka内部主题__consumer_offsets中，通过对group.id的hash取模获取在哪个分区中获取信息。

目前，Kafka为某个Consumer Group确定Coordinator所在的Broker的算法有2个步骤。
第1步：确定由__consumer_offsets主题的哪个分区来保存该Group数据：partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)。
第2步：找出该分区Leader副本所在的Broker，该Broker即为对应的Coordinator。
首先，Kafka会计算该Group的group.id参数的哈希值。
比如你有个Group的group.id设置成了test-group，那么它的hashCode值就应该是627841412。
其次，Kafka会计算__consumer_offsets的分区数，通常是50个分区，之后将刚才那个哈希值对分区数进行取模加求绝对值计算，即abs(627841412 % 50) = 12。
此时，我们就知道了__consumer_offsets主题的分区12负责保存这个Group的数据。
有了分区号，我们只需要找出__consumer_offsets主题分区12的Leader副本在哪个Broker上就可以了，这个Broker，就是我们要找的Coordinator。

消费完成后可以自动或者手动提交偏移量offset。过早提交偏移量可能导致消费消息丢失，过晚提交偏移量可能导致重复消费消息。
自动提交会有重复消费的问题，但是不阻塞consumer。手动提交灵活，但是阻塞consumer。
偏移量offset保存在ZooKeeper外部系统的做法，最显而易见的好处就是减少了Kafka Broker端的状态保存开销。
不过，慢慢地发现了一个问题，即ZooKeeper这类元框架其实并不适合进行频繁的写更新，而Consumer Group的位移更新却是一个非常频繁的操作。

这种大吞吐量的写操作会极大地拖慢ZooKeeper集群的性能。
于是，在新版本的Consumer Group中，Kafka社区重新设计了Consumer Group的位移管理方式，采用了将位移保存在Kafka内部主题的方法。
这个内部主题就是__consumer_offsets，默认该主题的分区数是50，副本数是3。该主题消息会无限积压导致磁盘过大，所以有Compact清除策略，对于相同key的消息会保留最新的，做这个操作的线程是Log Cleaner线程。

活锁的概念：消费者持续的维持心跳，但没有进行消息处理。
为了预防消费者在活锁情况一直持有分区，通常会利用max.poll.interval.ms活跃检测机制，如果调用 Poll 的频率大于最大间隔，那么消费者将会主动离开消费组，以便其他消费者接管该分区

## kafka消息压缩
消息压缩是在业务主线程 KafkaProducer 完成的，消息的压缩大大减少了本地内存、网络通信和服务端存储的压力。有两种格式V1和V2，V2是进行优化，比如将公共部分抽取到消息集合外，节省CRC校验时间；
有两种情况会导致Borker端重新进行压缩：Broker端指定了和Producer端不同的压缩算法；Broker端发生了消息格式转换。
基本过程：Producer端压缩、Broker端保持、Consumer端解压缩。
压缩算法：
在Kafka 2.1.0版本之前，Kafka支持3种压缩算法：GZIP、Snappy和LZ4。
从2.1.0开始，Kafka正式支持Zstandard算法（简写为zstd）。
它是Facebook开源的一个压缩算法，能够提供超高的压缩比。
在实际使用中，GZIP、Snappy、LZ4和zstd的表现各有千秋。
但对于Kafka而言，在吞吐量方面：LZ4 > Snappy > zstd和GZIP；而在压缩比方面，zstd > LZ4 > GZIP > Snappy。
具体到物理资源，使用Snappy算法占用的网络带宽最多，zstd最少；
在CPU使用率方面，各个算法表现得差不多，只是在压缩时Snappy算法使用的CPU较多一些，而在解压缩时GZIP算法则可能使用更多的CPU。

## KafKa消息丢失和重复，有序
1. 最多一次（At most once）：对应消息不重复。消息最多传递一次，消息有可能会丢，但不会重复。一般运用于高并发量、高吞吐，但是对于消息的丢失不是很敏感的场景。
2. 最少一次（At least once）：对应消息不丢失。消息最少传递一次，消息不会丢，但有可能重复。一般用于并发量一般，对于消息重复传递不敏感的场景。
3. 有且仅有一次（Exactly once）：每条消息只会被传递一次，消息不会丢失，也不会重复。 用于对消息可靠性要求高，且对吞吐量要求不高的场景。
是实现语义，不是配置

1.不丢失：
生产端：
第一个，要使用带回调方法的 API
Future<RecordMetadata> send(ProducerRecord<K, V> record, Callback callback)

第二个，设置参数 acks=-1
acks=0，表示生产者不等待任何服务器节点的响应，只要发送消息就认为成功。
acks=1，表示生产者收到 leader 分区的响应就认为发送成功。
acks=-1，表示只有当 ISR（同步副本机制）中的副本全部收到消息时，生产者才会认为消息生产成功了。这种配置是最安全的，因为如果 leader 副本挂了，当 follower 副本被选为 leader 副本时，消息也不会丢失。但是系统吞吐量会降低，因为生产者要等待所有副本都收到消息后才能再次发送消息。

第三个，设置参数 retries=3
生产消息如果重试失败了，对异常处理时就可以把消息保存到其他可靠的地方，如磁盘、数据库、远程缓存等，然后等到服务正常了再继续发送消息。
第四个，设置参数 retry.backoff.ms=300

服务端：
第一个，设置 replication.factor >1

第二个，设置 min.insync.replicas >1

第三个，设置 unclean.leader.election.enable = false

消费端：
第一个，设置 enable.auto.commit=false

第二个，要有手动提交偏移量的正确步骤

2.不重复：
生产端：
从 0.11.0 的版本开始，Kafka 给每个生产端生成一个唯一的 ID，并且在每条消息中生成一个 sequence num，sequence num 是递增且唯一的，这样就能对消息去重，达到一个生产端不重复发送一条消息的目的。
但是这个方法是有局限性的，只对在一个生产端内生产的消息有效，如果一个消息分别在两个生产端发送就不行了，还是会造成消息的重复发送。好在这种可能性比较小，因为消息的重试一般会在一个生产端内进行。当然，对应一个消息分别在两个生产端发送的请求我们也有方案，只是要多做一些补偿的工作，比如，我们可以为每一个消息分配一个全局 ID，并把全局 ID 存放在远程缓存或关系型数据库里，这样在发送前可以判断一下是否已经发送过了。

消费端：
幂等，比如生成消息唯一标识，在Redis中进行缓存，缓存时间大于max.poll.interval.ms的两次poll间隔检查时间。

有序：
1、可以设置topic，有且只有一个partition
2、根据业务需要，需要顺序的 指定为同一个partition
3、根据业务需要，比如同一个订单，使用同一个key，可以保证分配到同一个partition上

## spring.@KafkaListener 和 @StreamListener
@StreamListener(Sink.INPUT) 是一个注解，用于 Spring Cloud Stream 框架中。它的作用是将一个方法标记为消息流的监听器，用于处理来自消息代理（如 Kafka 或 RabbitMQ）的输入消息。

@EnableBinding(Sink.class) 注解用于启用与输入通道的绑定。


