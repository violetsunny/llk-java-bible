## 负载均衡架构
在实际的服务代理流程中，客户端首先通过DNS解析服务域名，获得服务的IP地址。然后，DNS返回的IP地址可能是LVS/F5负载均衡器的地址。LVS/F5根据配置的策略将请求转发到后端的Nginx服务器。最后，Nginx将请求路由到真正的服务实例，完成整个服务代理流程。
在一个由多台 Web 服务器组成的集群中，Keepalived 为集群分配一个虚拟 IP 地址。当客户端发送请求时，请求会被路由到虚拟 IP 地址所在的服务器上。Keepalived 会根据服务器的负载情况和健康状态，动态地将虚拟 IP 地址绑定到不同的服务器上，实现请求的均衡分发。Keepalived 通常与 Nginx 或 LVS（Linux Virtual Server）等负载均衡器结合使用，以提供 Web 服务的高可用性。

K8S可以在中小项目中直接使用，对于超大项目可以加入LVS等。

负载分为工作在网络第四层（传输层）和网络第七层（应用层）：
四层（传输层）：支持对TCP，UDP协议负载。例如：LVS,F5,HAProxy
七层（应用层）:支持HTTP,HTTPS,FTP,SMTP等。例如：Nginx,F5,HAProxy
硬负载：F5 BIG-IP、Citrix NetScaler
软负载：Nginx,LVS,HAProxy

## nginx
服务器代理框架，七层（应用层）,可通过ip_hash 实现长连接会话保持。

Nginx是一个 轻量级/高性能的反向代理Web服务器，用于 HTTP、HTTPS、SMTP、POP3 和 IMAP 协议。采用异步非阻塞的事件驱动模型，能够高效地处理大量并发连接。他实现非常高效的反向代理、负载平衡，他可以处理2-3万并发连接数，官方监测能支持5万并发。
优点：
1. 跨平台、配置简单，支持ssl加密，缓存。
2. 非阻塞、高并发连接：处理 2-3 万并发连接数，官方监测能支持 5 万并发。
3. 内存消耗小，支持压缩：开启 10 个 Nginx 才占 150M 内存。
4. 成本低廉，且开源。
5. 稳定性高，宕机的概率非常小。
6. 内置的健康检查功能：如果有一个服务器宕机，会做一个健康检查，再发送的请求就不会发送到宕机的服务器了。重新将请求提交到其他的节点上。
场景：
1. http服务器。Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。
2. 虚拟主机。可以实现在一台服务器虚拟出多个网站，例如个人网站使用的虚拟机。
3. 反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要用多台服务器集群可以使用nginx做反向代理。并且多台服务器可以平均分担负载，不会应为某台服务器负载高宕机而某台服务器闲置的情况。
4. nginx中也可以配置安全管理、比如可以使用Nginx搭建API接口网关,对每个接口服务进行拦截。
5. 支持 HTTP Live Streaming（HLS）和 Dynamic Adaptive Streaming over HTTP（DASH）等协议。它可以将视频文件分割成小的片段，并通过 HTTP 协议进行传输，实现视频的实时播放和点播。

如何高并发：
Nginx 每进来一个 request ，会有一个 worker 进程去处理。但不是全程的处理，处理到可能发生阻塞的地方，比如向上游（后端）服务器转发 request ，并等待请求返回。那么，这个处理的 worker 不会这么傻等着，他会在发送完请求后，注册一个事件：“如果 upstream 返回了，告诉我一声，我再接着干”。于是他就休息去了。此时，如果再有 request 进来，他就可以很快再按这种方式处理。而一旦上游服务器返回了，就会触发这个事件，worker 才会来接手，这个 request 才会接着往下走。
这就是为什么说，Nginx 基于事件模型。

由于 web server 的工作性质决定了每个 request 的大部份生命都是在网络传输中，实际上花费在 server 机器上的时间片不多。这是几个进程就解决高并发的秘密所在。即：
webserver 刚好属于网络 IO 密集型应用，不算是计算密集型。
异步，非阻塞，使用 epoll ，和大量细节处的优化。也正是 Nginx 之所以然的技术基石。

ng负载算法：
1. 轮询(默认)
2. 最小连接数
2. 加权 weight （加权轮询，加权最小连接）
3. ip_hash( IP绑定)源地址散列
4. 最短响应时间
5. url_hash

## Nginx其他主要功能
动静分离：
location /image/ {
root   /usr/local/static/;
autoindex on;
}
可以通过映射路径转换为访问ng本地文件

跨域：
使用Nginx转发请求。把跨域的接口写成调本域的接口，然后将这些接口转发到真正的请求地址。

虚拟主机：
基于端口的虚拟主机
当客户端访问www.lijie.com,监听端口号为8080,直接跳转到data/www目录下文件
server {
listen       8080;
server_name  www.lijie.com;
location / {
root   data/www;
index  index.html index.htm;
}
}
当客户端访问www.lijie.com,监听端口号为80直接跳转到真实ip服务器地址 127.0.0.1:8080
server {
listen       80;
server_name  `www.lijie.com`;
location / {
proxy_pass `http://127.0.0.1:8080`;
index  index.html index.htm;
}
}

限流：
Nginx限流就是限制用户请求速度，防止服务器受不了
限流有3种
正常限制访问频率（正常流量）
突发限制访问频率（突发流量）
限制并发连接数
Nginx中使用ngx_http_limit_req_module模块来限制的访问频率，限制的原理实质是基于漏桶算法原理来实现的。

在有多个cpu的情况下，可以设置多个worker，worker进程的数量可以设置到和cpu的核心数一样多，如果在单个cpu上起多个worker进程，那么操作系统会在多个worker之间进行调度，这种情况会降低系统性能，如果只有一个cpu，那么只启动一个worker进程就可以了。

## DNS
域名系统，域名类似一个树结构，顶级域名，二级域名，三级域名等，使用递归或者迭代查询的方式从域名服务器中到IP。是针对请求Client的。
1.域名解析，像一个电话簿找到域名对应的IP
2.负载均衡，域名对应多个ip时可以进行负载
3.故障转移，可以通过与解析转移故障服务到备服务

域名服务器
域名服务器是存储域名和 IP 地址对应关系的计算机系统。主要分为根域名服务器、顶级域名服务器、权威域名服务器和本地域名服务器。
根域名服务器：全球共有 13 组根域名服务器，负责管理顶级域名服务器的地址信息。
顶级域名服务器：负责管理特定顶级域名（如 “.com”、“.cn” 等）的域名服务器。
权威域名服务器：由各个域名注册商或网站管理员负责维护，存储特定域名的详细 IP 地址信息。
本地域名服务器：通常由互联网服务提供商（ISP）提供，为用户的计算机提供域名解析服务。当用户的计算机需要解析一个域名时，首先会向本地域名服务器发送请求。例如，当你使用家庭宽带上网时，本地域名服务器可能位于你的宽带运营商的数据中心。

## Haproxy
高可用性、负载均衡以及基于TCP(第四层)和HTTP(第七层)应用的代理，四层（传输层），七层（应用层）
HAProxy 可以有效地处理数以万计的并发请求.
支持多种负载均衡算法，包括轮询、加权轮询、最少连接数、源 IP 哈希（ip_hash）等。
多种方式进行健康检查，如 TCP 连接检查、HTTP 请求检查等。
提供了一些安全功能，如 SSL 终止、HTTP 基本认证等。
支持会话保持。

特别是数据库读写分离的场景下，HAProxy 可以将读请求分发到多个只读数据库实例上，将写请求分发到主数据库实例上，实现负载均衡和高可用性。

## F5
F5是一种负载均衡硬件，工作在网络的第四层（传输层）和第七层（应用层），与LVS提供的能力类似，性能比LVS更高，但价格昂贵。是应用交付控制器（Application Delivery Controller，ADC）

支持多种负载均衡算法，如轮询、加权轮询、最少连接数等
Web 应用防火墙（WAF）、分布式拒绝服务（DDoS）攻击防护
支持流量整形、限速等策略
支持会话保持
实时监测服务器状态，自动隔离故障服务器。支持冗余电源、冗余风扇和热插拔组件等，确保在硬件故障时系统仍能持续运行。如设备集群、会话同步等，可以在设备故障或网络中断时实现无缝切换，保证应用的连续性。

## LVS（Linux Virtual Server）
基于Linux虚拟服务器，四层（传输层），通过IP地址和端口号进行负载均衡，支持TCP，UDP。

LVS是软件，运行在操作系统内核态，可对TCP请求或更高层级的网络协议进行转发，因此支持的协议更丰富，并且性能也远高于Nginx，可假设单机的LVS可支持几十万个并发的请求转发；
通过与Keepalived等高可用性工具结合使用，LVS可以确保服务的持续运行。
支持多种负载均衡算法，如轮询（Round Robin）、加权轮询（Weighted Round Robin）、最少连接（Least Connections）、加权最少连接（Weighted Least Connections），源地址散列（ip_hash），最短延迟等。
支持会话保持，也被称为持久连接（persistence）

在分布式文件系统中，LVS 可以用于文件服务器的负载均衡。

## KeepAlived
容器管理工具：部署，自动扩容，负载均衡；第三层（网络层）、第四层（传输层）和第五层（应用层）；
网络层（Layer 3），Keepalived 使用 ICMP 数据包（类似于 ping 命令）来检查服务器的 IP 地址是否活跃。
传输层（Layer 4），Keepalived 检查 TCP 端口的状态，例如 Web 服务器通常使用端口 80，如果端口不活跃，则认为服务器出现问题
应用层（Layer 7），Keepalived 可以执行更复杂的检查，例如通过 HTTP GET 请求来测试 Web 服务器的响应

通过 VRRP（Virtual Router Redundancy Protocol，虚拟路由冗余协议）来实现，允许在一组服务器之间共享一个虚拟 IP 地址。Keepalived 可以监控服务器的状态，当主服务器出现故障时，Keepalived 能够自动将流量切换到备用服务器，确保服务的连续性和可用性。这种机制使得 Keepalived 成为构建高可用集群时的重要组件，尤其是在需要故障转移和负载均衡的场景中。

可使用keepalived软件模拟出虚拟IP，然后把虚拟IP绑定到多台LVS/Nginx服务器上，浏览器访问虚拟IP时，会被路由器重定向到真实的LVS/Nginx服务器，当主LVS/Nginx服务器宕机时，keepalived软件会自动更新路由器中的路由表，把虚拟IP重定向到另外一台正常的LVS服务器，从而达到LVS/Nginx服务器高可用的效果。

## K8s
为容器服务而生的一个可移植容器的编排管理工具，K8S的负载均衡方案有三种:Ingress(和Nginx很像)、kube-proxy(userspace)(iptables(防火墙)和ipvs（IP Virtual Server负载均衡）)。

Kubernetes的架构主要由以下几个核心组件构成：
Master节点：负责整个集群的管理和调度。它包括API Server、Scheduler、Controller Manager和etcd（存储集群状态）。
Node节点：运行容器化应用程序的工作节点,可以是物理机或虚拟机。每个Node节点上运行着kubelet、kube-proxy（iptables模式（Linux 内核防火墙功能，提供了丰富的数据包处理和过滤能力）和ipvs模式（ Linux 内核的一部分专门用于实现负载均衡，可以更高效地处理大量连接和高并发请求））和容器运行时（如Docker）。
Pods：Kubernetes的基本部署单元，可以包含一个或多个容器。
Services：定义一组Pod的逻辑集合，通过一个固定的IP和端口提供访问。
Deployments：管理Pod的部署和更新。
StatefulSets：用于管理有状态的应用程序。
Ingress：管理外部访问应用的HTTP和HTTPS路由。
ConfigMaps和Secrets：存储配置数据和敏感信息。

一、外部请求发起
用户或客户端发起请求：
用户通过浏览器、移动应用或其他客户端向特定的域名或 IP 地址发送请求。这个请求可能是 HTTP、HTTPS 或其他网络协议的请求。
例如，用户在浏览器中输入www.example.com，发起对一个网站的访问请求。
二、Ingress 接收请求
Ingress 作为入口：
Ingress 是 Kubernetes 集群中外部请求的入口点。它通常由一个 Ingress 控制器（如 Nginx Ingress Controller）实现，负责接收外部请求并根据配置的规则进行路由。
例如，Ingress 控制器根据请求的域名和 URL 路径，确定将请求转发到哪个 Kubernetes 服务。
三、服务发现与路由
服务发现：
Kubernetes 通过服务（Service）对象实现服务发现。Ingress 控制器根据配置的规则，查找对应的服务，并确定后端的 Pod 列表。
例如，Ingress 控制器发现请求应该转发到名为 “my-service” 的服务，然后查询 Kubernetes API 以获取该服务的后端 Pod 信息。
路由决策：
Ingress 控制器根据请求的特征（如域名、URL 路径、HTTP 方法等）和配置的规则，决定将请求路由到哪个具体的后端 Pod。
例如，如果请求的 URL 路径以/api/v1开头，Ingress 控制器可能将请求路由到一组特定的 API 服务 Pod。
四、服务负载均衡
服务对象与负载均衡：
Kubernetes 的服务对象负责实现负载均衡。当 Ingress 控制器将请求转发到服务时，服务会根据一定的负载均衡策略将请求分发到后端的多个 Pod 上。
例如，服务可以使用轮询（Round Robin）、最少连接数等负载均衡算法，将请求均匀地分发到后端的 Pod 上。
Pod 选择与请求分发：
服务根据负载均衡策略选择一个合适的后端 Pod，并将请求转发到该 Pod 上。这个过程可以通过 Kubernetes 的代理机制（如 kube-proxy）或直接由服务对象进行。
例如，服务选择一个当前负载较低的 Pod，并将请求通过网络转发到该 Pod 所在的节点。
五、Pod 处理请求
容器内应用处理请求：
请求最终到达后端的 Pod 上，Pod 中的容器内运行着具体的应用程序。应用程序接收请求并进行处理，执行相应的业务逻辑。
例如，Pod 中的 Web 应用程序接收到 HTTP 请求后，根据请求的内容进行数据库查询、业务计算等操作，并生成响应结果。
响应返回：
应用程序处理完请求后，将响应结果返回给请求的发起方。响应通过网络依次经过 Pod、服务、Ingress 控制器，最终返回给用户或客户端。
例如，应用程序生成一个 HTML 页面作为响应，并将其发送回客户端，客户端的浏览器显示该页面。

## TCP长连接负载均衡
长连接负载均衡粒度
与短连接每次请求都做负载均衡策略不同，长连接不光有请求粒度的负载均衡，还有连接粒度的负载均衡。

请求粒度负载均衡的实现方式是一个客户端与每个服务端都建立连接，发送请求时按照某种负载均衡策略选择一个服务端进行请求；连接粒度的负载均衡则是客户端在建立连接时按照某种负载均衡策略挑选一个节点进行建连，后续请求都发往这个节点。







如何选择主要是考量单个服务端可能的连接数量，如果连接数远不是瓶颈的时候（个人认为万级以下），可考虑请求粒度，否则连接粒度的负载均衡策略更佳。

举个例子，Dubbo 一个 Provider 节点和来自订阅 Consumer 的所有节点都建立了连接，前提是 Dubbo 一个 Provider 基本不太会可能被几万个节点消费，所以 Dubbo 可以做请求粒度的长连接负载均衡。但如果是 Nacos，所有需要服务发现的机器都要和 Nacos 服务端建立连接，长连接数量就和公司服务器数量级相关，规模大的情况，几万、上十万、百万也是有可能的，所以如果 Nacos 也像 Dubbo 那样设计，就无法支撑大规模服务发现了。

连接粒度的负载均衡
对于长连接，连接粒度的负载均衡问题遇到的更多。
连接数均衡：
由于连接建立之后，除非异常不会断开，所以问题就来了，如果某一个节点的连接数相比较其他节点要多出很多，这种就属于不均衡了。出现这种问题的情况最常见的就是服务端发布（重启）。重启时服务不可用，该节点原先的连接会断开，找到存活的节点进行连接，当这台服务起来时，它的连接数将非常少。如果是一轮发布，最先发布的机器最后连接数最多，最后发布的连接数最少。
这种情况下，我们可以调整建连的负载均衡算法为最小连接数模式，当服务重启完成后，后续的连接就能全部连接到此节点。
但这个方法并不总是奏效，因为服务在重启时，断开的连接已经和其他节点建立了连接。
这时我们可能需要额外的均衡手段，如定时从全局视角看各个节点的连接数是否均衡，如果不均衡则要断开最多连接的节点，直到平衡。
这里我们的客户端需要对连接的断开处理特别小心，当然我觉得这是必须的。
但也要说明一点，如果连接不是长时间保持的，额外的均衡手段可能就不需要了，等一会就自然平衡了。这种发生在什么情况呢？比如公网的长连接，客户端的网络情况没内网那么好，经常断开连接，这就相当于帮我们自动平滑连接了。
如果是内网服务，连接能一直保持，额外的平衡手段就显得有必要了。

服务器规格不同：
我们通常为了单机能保持更多的长连接，一般会选用物理机部署服务，有时候各个物理机规格不统一，如果我们的均衡手段一视同仁，每个节点连接数差不多，规格差的服务器可能压力就比其他机器大。
所以建连的负载均衡算法和额外的均衡手段也要考虑服务器规格，可以简单地把服务器规格与当前的连接数抽象为一个权重，客户端建连时加权再选择。

扩容无效问题：
我们的长连接服务理应是可水平扩容的，连接数变多，加机器就可以，我们的设计大多也是如此。
但有时候可能不小心，导致水平扩容无效。
举个例子，还是注册中心，假设有3个节点的注册中心集群，此时有 1w 个客户端连上来，订阅了各种各样的服务，由于客户端的数量远远大于注册中心节点，所以基本可以认为每个注册中心节点订阅的服务是差不多的，近似每个服务的变更，每个注册中心节点都要处理，CPU 消耗自然就多了。如果把注册中心节点扩容为5台，其实每台服务只是少了一点连接，但依然每个注册中心节点还是近乎要处理所有的服务变更。

这种情况下就要审视长连接服务设计的是否合理，一般采取分层的思想，长连接这层服务只专注推送，一般称为通道层或者 session 层，它并不支持复杂的计算逻辑。










如果设计有问题，短时间又没法修改，可以试试按照服务订阅者的名字路由到特定的服务端节点，保证同一个 Conusmer 只连同一个注册中心节点，这样某服务变更时，该节点只需要计算一次，就可以推送给所有 Conusmer，运气好的话，其他节点都不用计算。

现有中间件负载：
1. F5 BIG-IP 可以基于源 IP 地址、目标 IP 地址、端口号等多种因素进行流量分发，确保长连接能够均匀地分配到后端服务器上。
2. Nginx 可以通过配置 stream 模块来实现对 TCP 长连接的负载均衡。HAProxy 同样支持 TCP 负载均衡，并提供多种负载均衡算法可供选择。
3. Kubernetes中可以独立部署HAProxy或者Nginx来监听端口并转发给pod；或者通过NodePort创建一个特定端口进行暴露， Service 会在每个节点上暴露一个特定的端口，外部客户端可以通过任何节点的 IP 地址和这个端口来访问服务；LoadBalancer 类型的 Service，Kubernetes 会自动创建一个外部负载均衡器，并将其配置为将流量转发到 Service 后端的 Pod。
