## 常见数据结构
**线性表（顺序存储 arraylist，链式存储Linkedlist）、栈、队列、哈希表（散列表）**

线性表：数组[]实现，node链表

栈：先进后出。链表实现比较好

队列：先进先出，队尾进入，对头出。链表实现比较好，front==rear 的时候队列为空

哈希表：散列分布。

>哈希冲突：线性探测，冲突后寻找空位置。二次探测，增加线性探测的步长。双重散列，多种散列函数计算。链表法，冲突的追加一个链表。

- O(1) 代表已知常量级的时间复杂度，空间复杂度 in-place
- O(n) 代表线性级的时间复杂度，空间复杂度 out-place
- O(nlog n)代表n的对数阶的时间复杂度
- O(log n) 代表对数阶的时间复杂度
- O(n*n) 代表多层嵌套。 另外开辟空间的

## 常见集合类及应用场景
**List是线性表的结构，继承了Collection,Iterable接口，有序可重复  小知识：数组下标从0开始是为了cpu计算地址时减少运算。**
- LinkedList：双向链表实现,链表内存是散乱，每一个元素存储本身内存的同时还存下一个元素的地址，链表，增删快，查找慢。
- ArrayList：数组实现，非线程安全，1.5扩容,查询快，增删慢  连续的空间存储相同的数据。删除是先标记删除(软删除)，没有更多空间时真正删除。无参构造初始化容量为0，有参自定义，如果放入数据会让初始长度为10。最大为int的最大值减8（2^31-8），是因为jvm在数组中保留一些头信息，最大可能导致OOM。
- Vector：线程安全，2倍扩容
- List/Set 可以互转
- Set,继承了Collection,Iterable接口，无序不可重复。
- HashSet:底层由HashMap实现，（用了HashCode,equals），一般建议是final类，避免值改变导致重复。当你把对象加入HashSet时，HashSet 会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他加入的对象的 hashcode 值作比较，如果没有相符的 hashcode，HashSet 会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用equals()方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让加入操作成功。
- LinkedHashSet 链表
- SortedSet 排序
- TreeSet:红黑树，由平衡二叉树实现
- Query:实现类LinkedList
- ArrayDeque:双端队列，基于可变长数组和双指针来实现，不支持null，性能比LinkedList好
- PriorityQueue:小顶推，根据优先级出队，插入删除O(logn)，非线程安全。PriorityQueue(Comparator.reverseOrder());大顶堆


**Map，K-V结构，K是set  EntrySet继承了Collection,Iterable接口**
- HashMap:非线程安全，高效，null,链表散列，底层是阈值为8的时候，链表和红黑树互转。
- WeakHashMap：当某个键不再正常使用时，会从WeakHashMap中被自动移除，可以节省内存
- HashTable:线程安全，低效，不支持null，锁整个表，性能差
- SortedMap：TreeMap,默认是按 key 的升序排序
- LinkedHashMap:removeEldestEntry是在put时调用的，可以根据判断返回值删除末尾的数值
- ConcurrentHashMap：线程安全的HashMap
- BitMap:位图，存的bit值，多次hash去重数据
- ConcurrentSkipListMap: 跳表，O(logn)，跳表的本质是同时维护了多个链表，并且链表是分层的。跳表是一种利用空间换时间的算法。

## HashMap 1.7和1.8
**HashMap 实现原理： 
数组+链表/红黑树，通过hashcode寻找链表，再通过key的比较找到对应entry。Node[]**

>hash算法: (len-1) & (hashcode ^ (hashcode >> 16)) ，h& (length-1)等价于h%length
长度是2的n次方是为了让减1后的二进制都是111...这样与运算才能快速拿到数组下标。扩容的时候，转换二进制后，可以方便移动元素。
key一般是final类，key创建的时候 hashcode 就被缓存了，不需要重新计算。

数据结构区别：
1. JDK1.7的时候使用的是数组+ 单链表的数据结构，头插法，可能形成环。恶意将hash值相同会导致退化成链表。
2. 但是在JDK1.8及之后时，使用的是数组+链表/红黑树的数据结构（当链表的深度达到8且数组元素>=64个的时候，就会自动扩容把链表转成红黑树的数据结构来把时间复杂度从O（n）变成O（logN）提高了效率，否则先考虑扩容数组），采用尾插法。使用红黑树是为了防止二叉树退化成线性结构的情况。
使用8是因为泊松分布，深度超过8的时候概率越小。
判断扩容是元素数量达到 (当前容量 * 加载因子) 时扩大一倍，加载因子0.75是因为空间和时间折中，1的话空间浪费少但是时间长，数组越大越浪费性能，空间换时间
扩容移位是按照高位和低位是key的hash和容器大小的与运算，容器大小是2的n次方，所以结果不是0就是容器大小，等于0为低位不移动，另外为高位移动。
put方法，先判断是否需要扩容，在判断是否key冲突，key是否存在，是否是红黑树，是否需要转红黑树，然后插入。


扩容区别：
1. dk1.7默认大小16，factor=0.75, 元素长度大于阈值12扩容一倍，rehash,重新计算元素下标。高并发扩容会造成环。
2. jdk1.8默认大小16，factor=0.75, 元素长度大于阈值12扩容一倍；链表长度超过8且数组元素小于64时扩容，链表转红黑树，小于6会转成链表。
两倍扩容，创建新的tab数组进行挪动。如果当前位置是没有冲突的，就进行hash&(新的长度-1)算数组下标。 如果是链表，进行hash&原长度算高低位，等于0是低位保持不变，否则当前下标+原长度，挪到新的位置。如果是红黑树，先进行算高低位，判断是否挪动，然后再进行判断是否小于等于6进行转链表。

`computeIfAbsent` 如果不存在则放入
`computeIfPresent` 如果存在则放入
`compute` 如果不存在则删除key，如果存在则放入

````
扩容算法：        
假设传进来一个数的二进制是100001001；
n |= n >>> 1;
在这里处理之后是110001101，这一步可以这样理解，
如果你是1，那么把你的下一位变成1，那么是不是有1的地方会存在两个1，
这也就解释了为什么下一行要无符号右移2，依此类推1，2，4，8，16，下下次直接右移4.
n |= n >>> 2;
在这里处理之后是111101111
n |= n >>> 4;
在这里处理之后是111111111
n |= n >>> 8;
n |= n >>> 16;
处理完之后，必然是全1，也就是2幂-1，那么返回n+1
int n = cap - 1;
这一步是为了防止传入的cap本来就是2的幂，结果处理成2n+1了。
结果为2的n次方。

“取余(%)操作中如果除数是 2 的幂次则等价于与其除数减一的与(&)操作（也就是说 hash%length==hash&(length-1)的前提是 length 是 2 的 n 次方；）。” 并且 采用二进制位操作 &，相对于%能够提高运算效率，这就解释了 HashMap 的长度为什么是 2 的幂次方。
2 的 N 次幂有助于减少碰撞的几率。如果 length 为2的幂次方，则 length-1 转化为二进制必定是11111……的形式，在与h的二进制与操作效率会非常的快，而且空间不浪费。
````

## 二叉树
**`根节点`--`叶子节点`  `父节点`--`子节点`**

>数的高度：根节点到叶子节点的最长路径  数的深度：根节点到叶子节点的边数  层数为深度+1

`完全二叉树`：是叶子节点再最后两层，最后叶子节点靠左分布，倒数第二层达到最满。O(logn)

链式存储，左右指针。数组存储：父是i,左子树为2i,右子数为2i+1

`平衡二叉树(AVL)`是高度之差的绝对值不超过1 满足条件会进行左旋和右旋 高度为Log2(n+1),其查找效率为O(Logn)

左旋是将左子节点作为新的根节点，前根节点作为新根节点的右子节点，前根节点的左子节点的右子节点作为新根右子节点的左子节点。 右旋同理。

`不平衡二叉排序树`的查找性能在O(Logn)到O(n)之间

`二叉搜索树`的中序遍历就是一个有序序列

>广度优先搜索(breadth-first-search)、深度优先搜索(depth-first-search)，以及中序遍历（左中右）、后序遍历（左右中）和前序遍历（中左右）、层序遍历

````
广度 BFS：
通过边依次往后搜索，全部遍历
queue存储已经被访问的但是相连顶点没有被访问的顶点 visited记录已经被访问的顶点 prev用来记录搜索路径

可以使用队列实现，将顶点放入队列中，取出顶点的后续节点放入队列中，依次类推。

深度 DFS：一路走到黑知道没有后续节点，再回溯上一个顶点继续。 需要一个变量标识
搜索后找不到就折回继续搜索
queue存储已经被访问的但是相连顶点没有被访问的顶点 visited记录已经被访问的顶点 prev用来记录搜索路径

就是递归访问我能访问的所有节点然后比较。

可以用栈实现，顶点后续节点放入栈中，取出栈顶元素，放入该元素的后续元素，依次类推达到遍历所有元素的目的。
````

## 红黑树
自平衡二叉查找树
红黑树的时间复杂度为: O(log n);
一棵含有n个节点的红黑树的高度至多为2log(n+1);

特点：
（1）每个节点或者是黑色，或者是红色。
（2）根节点是黑色。
（3）每个叶子节点（NIL）是黑色。 [注意：这里叶子节点，是指为空(NIL或NULL)的叶子节点！]
（4）如果一个节点是红色的，则它的子节点必须是黑色的。
（5）从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。

左旋/右旋

## 堆
1.完全二叉树
2.任意节点的值大于等于（小于等于）子树的任意值  大顶堆是节点>=子节点 小顶堆是节点<=子节点
时间复杂度 O(logn)
堆化：从下往上，从上往下  找父节点是当前下标右移一位  数组存储
添加 从下往上
1.先放入最后的位置
2.在与父节点比较，不符合（大顶堆是比父节点大，小顶堆是比父节点小）进行互换，直到符合。

删除 从上往下
1.删除节点，将最后的节点移动到删除节点位置。
2.再进行比较，直到符合

推排序：小顶堆1.取出根节点。2.删除后的堆化。以此类推。
DelayedWorkQueue基于堆的数据结构

## B+树
1.内节点存关键字，叶子节点存key和数据  根节点可以是内节点也可以是叶子节点
2.m阶B+树，每个内节点存m-1个key
3.内节点的key都是按顺序排列，key的左子节点的key都要小于它，右子节点的key都要大于它。
4.叶子节点的数据都是指针指向的，双向链表

优点：
磁盘IO少，查询效率相同都是根节点往下，方便区间查找

缺点：
根节点如果就是叶子节点，会退化成链表 （应该数据特别少的情况）
主键不递增会产生大量的数据迁移和空间碎片
大量写请求随机，随机IO

B+树的插入是先在叶子节点上插入一个数据（key-data）。当超过m-1的个数时(m=16乘1024除主键大小+1，一个节点可以存16K的数),m/2的key将会晋升为内节点，并指向左子节点（m/2小）和右子节点(m/2大)。并以此类推。

和B树区别：
B树是所有节点存key和data，叶子节点没有相邻指向指针，B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。

## LSM树
相邻结构合并，减少查询数据的多次磁盘寻道。顺序写，不可变结构。不可变结构一般都是追加日志的方式进行存储，强调写入性能。K-v结构

## B树
B树是为了解决搜索树（BST）等结构在 HDD 磁盘上性能差而产生的，结构特点是高度很低，宽度很宽。检索的时候从上到下查找次数较少，甚至如 B+ 树那样，可以完全把非叶子节点加载到内存中，从而使查找最多只进行一次磁盘操作。在高度不变的情况下，这个 B+ 树一定会横向发展，从而使原有的一个节点分裂为多个节点。而 InnoDB 使用缓存的模式就是：为这种分裂预留一部分内存页面，用来容纳可能的节点分裂。

B树的变种，BW树是不可变结构。

## 图
图就是由顶点的有穷非空集合和顶点之间的边组成的集合。通常表示为：G(V,E)，其中，G表示一个图，V表示顶点的集合，E表示边的集合。

1. 每个元素称为顶点，每个元素之间的连接是边，一个元素有几个边就是几个度。
2.
   - 无向图
   - 有向图 无向图加方向。入度是有几个边指向该元素，出度就是该元素有几个边指向其他元素
   - 带权图 无向图，每个边加个权重。

存储方式：
邻接矩阵存储图  二维数组：无向图是有边值是1，有向图需要出度才是1，带权图是有边值为权重
连接表存储图  数组加链表，顶点为数组，指向关系边为链表。
数据是要存两次的 数据和值存两次，代表两者的关系

## 布隆过滤器
1. 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。
2. 根据得到的哈希值，在位Bit数组中把对应下标的值置为 1。

布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。

